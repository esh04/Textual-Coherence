{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9ZKbXs3MpFzQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import argparse\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchtext\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_4iAL3nrcE4",
        "outputId": "852fd738-8edc-4e18-c10a-dd47ba632ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipnTRok-pAKK",
        "outputId": "1e13ddd1-e395-4ff9-ef02-ea2e8283854e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "sw = stopwords.words('english') \n",
        "\n",
        "\n",
        "class Tokenizer:\n",
        "\n",
        "    def __init__(self, file, threshold=5):\n",
        "        self.file = file\n",
        "        self.data = pd.read_csv(file)\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def preprocess(self):\n",
        "        tokenizer = torchtext.data.utils.get_tokenizer('spacy', language='en')\n",
        "        tokens = []\n",
        "        sentence_list=[]\n",
        "        for text in self.data['text'].tolist():\n",
        "            tokens.append(tokenizer(text))\n",
        "            sentence_list.append(text.split('.'))\n",
        "\n",
        "        self.data['sentences_list'] = sentence_list\n",
        "        counter = Counter()\n",
        "        for line in tokens:\n",
        "            for word in line:\n",
        "                counter[word] += 1\n",
        "\n",
        "        mapper = {word[0]: idx+1 for idx,\n",
        "                  word in enumerate(counter.most_common())}\n",
        "        inverse_mapper = {idx+1: word[0] for idx,\n",
        "                          word in enumerate(counter.most_common())}\n",
        "\n",
        "        # sos_idx = len(counter_threshold.keys())\n",
        "        # eos_idx = len(counter_threshold.keys()) + 1\n",
        "        other_idx = len(counter.keys())\n",
        "\n",
        "        mapped_tokens = []\n",
        "\n",
        "        for line in tokens:\n",
        "            mapped_line = []\n",
        "            for word in line:\n",
        "              # map words to their mappings and to other otherwise\n",
        "                mapped_line.append(mapper.get(word, other_idx))\n",
        "            mapped_tokens.append(mapped_line)\n",
        "\n",
        "        return mapped_tokens, inverse_mapper\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def similarity_paragraph(data):\n",
        "    # data = self.data\n",
        "    sim_list = []\n",
        "    for para in data['sentences_list'].tolist():\n",
        "      sim = 200\n",
        "      start = para[0]\n",
        "      para = para[1:]\n",
        "      for sent in para:            \n",
        "        # tokenization\n",
        "        X_list = word_tokenize(start) \n",
        "        Y_list = word_tokenize(sent)\n",
        "          \n",
        "        # sw contains the list of stopwords\n",
        "        l1 =[];l2 =[]\n",
        "          \n",
        "        # remove stop words from the string\n",
        "        X_set = {w for w in X_list if not w in sw} \n",
        "        Y_set = {w for w in Y_list if not w in sw}\n",
        "          \n",
        "        # form a set containing keywords of both strings \n",
        "        rvector = X_set.union(Y_set) \n",
        "        for w in rvector:\n",
        "            if w in X_set: l1.append(1) # create a vector\n",
        "            else: l1.append(0)\n",
        "            if w in Y_set: l2.append(1)\n",
        "            else: l2.append(0)\n",
        "        c = 0\n",
        "          \n",
        "        # cosine formula \n",
        "        for i in range(len(rvector)):\n",
        "            c+= l1[i]*l2[i]\n",
        "        try:\n",
        "          cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
        "          if sim > cosine:\n",
        "            sim = cosine\n",
        "        except:\n",
        "          sim += 0\n",
        "          \n",
        "        start = sent\n",
        "      \n",
        "      # sim = sim/(len(para)+1)\n",
        "      sim_list.append(sim)\n",
        "    \n",
        "    data['similarity'] = sim_list\n",
        "\n",
        "    return data\n",
        "          \n",
        "          # print(\"similarity: \", cosine)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data from the GCDC Corpus consists of 4 sets of data each containing 1000 training entries and 200 test entries. Due to lack of data, we train on the 4 training sets and 3 of the test sets and use a single test set to test the results. We also compare the results obtained by each set.\n"
      ],
      "metadata": {
        "id": "Q2CypOZL2KiQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LRLl-EAOeCL"
      },
      "outputs": [],
      "source": [
        "# training data\n",
        "data1 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Clinton_train.csv')\n",
        "data2 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Yahoo_train.csv')\n",
        "data3 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Yelp_train.csv')\n",
        "data4 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Enron_train.csv')\n",
        "\n",
        "data5 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Yahoo_test.csv')\n",
        "data6 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Yelp_test.csv')\n",
        "data7 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Enron_test.csv')\n",
        "data8 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Enron_test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0m7bl6PO1oL"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([data1, data2, data3, data4, data5, data6, data7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixt94NWwP8Hi"
      },
      "outputs": [],
      "source": [
        "data.to_csv('/content/gdrive/MyDrive/NLP-Project/GCDC_Corpus_v2/GCDC_rerelease/new_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGJivFqTNcF6"
      },
      "outputs": [],
      "source": [
        "train = Tokenizer(\"/content/gdrive/MyDrive/GCDC_rerelease/new_train.csv\")\n",
        "test = Tokenizer(\"/content/gdrive/MyDrive/GCDC_rerelease/Clinton_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HowKzJMQLOM"
      },
      "outputs": [],
      "source": [
        "train = Tokenizer(\"/content/gdrive/MyDrive/NLP-Project/GCDC_Corpus_v2/GCDC_rerelease/new_train.csv\")\n",
        "test = Tokenizer(\"/content/gdrive/MyDrive/NLP-Project/GCDC_Corpus_v2/GCDC_rerelease/Clinton_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yS39RPLu83j"
      },
      "outputs": [],
      "source": [
        "lst = array(train.data['labelA'])\n",
        "encoded = to_categorical(lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK2UhBczvhRW"
      },
      "outputs": [],
      "source": [
        "lst = array(test.data['labelA'])\n",
        "t_encoded = to_categorical(lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONuCV7pSqCTb"
      },
      "outputs": [],
      "source": [
        "train_mapping, inv_train_mapping = train.preprocess()\n",
        "test_mapping, inv_test_mapping = test.preprocess()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarity Function finds the similarity of adjacent sentences in the paragraph and returns the least of all the similarity values."
      ],
      "metadata": {
        "id": "ZlC9kChW1kg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.data = similarity_paragraph(train.data)\n",
        "test.data = similarity_paragraph(test.data)"
      ],
      "metadata": {
        "id": "UACemeFn1kOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqDO2UAwnFvA"
      },
      "outputs": [],
      "source": [
        "train.data['encoding'] = train_mapping\n",
        "test.data['encoding'] = test_mapping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.data['labelA'][4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7gs41YO2XHr",
        "outputId": "86860d72-6fc7-428a-d928-cb61f44dd476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM with 4600/200 train/test(Clinton) split 3-way multi-classifier"
      ],
      "metadata": {
        "id": "arrSsQIZZaVg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17dg4rpmop0R"
      },
      "outputs": [],
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train.data['encoding'],maxlen = 500)\n",
        "y_train = encoded\n",
        "X_test = sequence.pad_sequences(test.data['encoding'],maxlen=500)\n",
        "y_test = t_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNglJ5YJqIPd",
        "outputId": "adcf2a3c-0243-45de-ec61-afd21c0dcacb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 500, 32)           1280000   \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (None, 500, 32)           8320      \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,772\n",
            "Trainable params: 1,296,772\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "200/200 [==============================] - 8s 28ms/step - loss: 1.0776 - accuracy: 0.4687\n",
            "Epoch 2/15\n",
            "200/200 [==============================] - 6s 29ms/step - loss: 1.0410 - accuracy: 0.4791\n",
            "Epoch 3/15\n",
            "200/200 [==============================] - 6s 32ms/step - loss: 0.9238 - accuracy: 0.5880\n",
            "Epoch 4/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.6298 - accuracy: 0.7478\n",
            "Epoch 5/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.3348 - accuracy: 0.8852\n",
            "Epoch 6/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.1780 - accuracy: 0.9415\n",
            "Epoch 7/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.1034 - accuracy: 0.9700\n",
            "Epoch 8/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0763 - accuracy: 0.9789\n",
            "Epoch 9/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0530 - accuracy: 0.9848\n",
            "Epoch 10/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0505 - accuracy: 0.9859\n",
            "Epoch 11/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0410 - accuracy: 0.9896\n",
            "Epoch 12/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0377 - accuracy: 0.9898\n",
            "Epoch 13/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0370 - accuracy: 0.9904\n",
            "Epoch 14/15\n",
            "200/200 [==============================] - 6s 28ms/step - loss: 0.0236 - accuracy: 0.9926\n",
            "Epoch 15/15\n",
            "200/200 [==============================] - 6s 28ms/step - loss: 0.0240 - accuracy: 0.9926\n",
            "Accuracy:  36.500000953674316\n"
          ]
        }
      ],
      "source": [
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(40000,embedding_vector_length,input_length = 500))\n",
        "model.add(LSTM(32,dropout=0.2, return_sequences = True ))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(4,activation = 'softmax'))\n",
        "model.compile(loss ='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train,y_train, epochs = 15, batch_size=23)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K_SWuGAecZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c3d297-0972-41b6-b443-f030b90d9203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://a18a4b47-e74c-4578-82bb-4804458e4475/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://a18a4b47-e74c-4578-82bb-4804458e4475/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fc8e4b1e590> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fc8e4b1d190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "filename = 'lstm_binary_min_sim_clinton.sav'\n",
        "pickle.dump(model,open(filename,'wb'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM with 4600/200 train/test(Clinton) split binary classifier with minimum similarity function"
      ],
      "metadata": {
        "id": "wQDhdJNofBZL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3lzA4pywwZ8"
      },
      "outputs": [],
      "source": [
        "coh_bin = []\n",
        "for i in range(4600):\n",
        "  if train.data['labelA'].tolist()[i] >=2:\n",
        "    coh_bin.append(1)\n",
        "  else:\n",
        "    coh_bin.append(0)\n",
        "train.data['bin_coh']= coh_bin\n",
        "\n",
        "\n",
        "coh_bin=[]\n",
        "for i in range(200):\n",
        "  if test.data['labelA'].tolist()[i] >=2:\n",
        "    coh_bin.append(1)\n",
        "  else:\n",
        "    coh_bin.append(0)\n",
        "\n",
        "test.data['bin_coh']=coh_bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q5r6H4yx3i_"
      },
      "outputs": [],
      "source": [
        "lst = array(train.data['bin_coh'])\n",
        "encoded = to_categorical(lst)\n",
        "\n",
        "lst = array(test.data['bin_coh'])\n",
        "t_encoded = to_categorical(lst)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dERcvIFyWF2"
      },
      "outputs": [],
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train.data['encoding'],maxlen = 500)\n",
        "y_train = encoded#train.data['h_e']\n",
        "X_test = sequence.pad_sequences(test.data['encoding'],maxlen=500)\n",
        "y_test = t_encoded#test.data['h_e']\n",
        "\n",
        "# X_train = np.append(train.data['similarity'][:,np.newaxis], X_train, axis=1)\n",
        "# X_test = np.append(test.data['similarity'][:,np.newaxis],X_test, axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-LghG347Nr-",
        "outputId": "aae6895e-3cc6-467a-a844-a5a3ab305f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "type(X_train)\n",
        "\n",
        "X_train = np.append(train.data['similarity'][:,np.newaxis], X_train, axis=1)\n",
        "X_test = np.append(test.data['similarity'][:,np.newaxis],X_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckWk6V9cyfWY",
        "outputId": "ad94dc60-139c-439e-a517-fa9b4d5e2bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 501, 32)           1280000   \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 501, 32)           8320      \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,706\n",
            "Trainable params: 1,296,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "200/200 [==============================] - 8s 28ms/step - loss: 0.6267 - accuracy: 0.6722\n",
            "Epoch 2/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.4904 - accuracy: 0.7685\n",
            "Epoch 3/15\n",
            "200/200 [==============================] - 6s 28ms/step - loss: 0.2560 - accuracy: 0.9037\n",
            "Epoch 4/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.1039 - accuracy: 0.9657\n",
            "Epoch 5/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0489 - accuracy: 0.9863\n",
            "Epoch 6/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0327 - accuracy: 0.9913\n",
            "Epoch 7/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0221 - accuracy: 0.9954\n",
            "Epoch 8/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0277 - accuracy: 0.9937\n",
            "Epoch 9/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0212 - accuracy: 0.9948\n",
            "Epoch 10/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0165 - accuracy: 0.9954\n",
            "Epoch 11/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0167 - accuracy: 0.9957\n",
            "Epoch 12/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0135 - accuracy: 0.9961\n",
            "Epoch 13/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0131 - accuracy: 0.9961\n",
            "Epoch 14/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0086 - accuracy: 0.9972\n",
            "Epoch 15/15\n",
            "200/200 [==============================] - 5s 27ms/step - loss: 0.0073 - accuracy: 0.9967\n",
            "Accuracy:  67.00000166893005\n"
          ]
        }
      ],
      "source": [
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(40000,embedding_vector_length,input_length = 501))\n",
        "model.add(LSTM(32,dropout=0.2, return_sequences = True ))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(2,activation = 'softmax'))\n",
        "model.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train,y_train, epochs = 15 , batch_size=23)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying different Hyperparameters to fine-tune the results"
      ],
      "metadata": {
        "id": "NRiRfhBdPL-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train.data['encoding'],maxlen = 256)\n",
        "y_train = encoded#train.data['h_e']\n",
        "X_test = sequence.pad_sequences(test.data['encoding'],maxlen=256)\n",
        "y_test = t_encoded#test.data['h_e']\n",
        "X_train = np.append(train.data['similarity'][:,np.newaxis], X_train, axis=1)\n",
        "X_test = np.append(test.data['similarity'][:,np.newaxis],X_test, axis=1)\n",
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(40000,embedding_vector_length,input_length = 257))\n",
        "model.add(LSTM(32,dropout=0.2, return_sequences = True ))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(2,activation = 'softmax'))\n",
        "model.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train,y_train, epochs = 10 , batch_size=23)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_hG-HU0cH5x",
        "outputId": "d02572ad-5078-4628-fd12-3c81bfeecdf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, 257, 32)           1280000   \n",
            "                                                                 \n",
            " lstm_30 (LSTM)              (None, 257, 32)           8320      \n",
            "                                                                 \n",
            " lstm_31 (LSTM)              (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,706\n",
            "Trainable params: 1,296,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 6s 17ms/step - loss: 0.6257 - accuracy: 0.6754\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 3s 16ms/step - loss: 0.4830 - accuracy: 0.7728\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 3s 16ms/step - loss: 0.2513 - accuracy: 0.9013\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 3s 16ms/step - loss: 0.1057 - accuracy: 0.9654\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 3s 16ms/step - loss: 0.0543 - accuracy: 0.9857\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 3s 16ms/step - loss: 0.0333 - accuracy: 0.9930\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 3s 16ms/step - loss: 0.0300 - accuracy: 0.9924\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 3s 16ms/step - loss: 0.0286 - accuracy: 0.9930\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 3s 16ms/step - loss: 0.0174 - accuracy: 0.9970\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 3s 17ms/step - loss: 0.0176 - accuracy: 0.9972\n",
            "Accuracy:  65.49999713897705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQgrSud3uSdc",
        "outputId": "7b89acbb-63bc-4026-9d08-de472209efea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 500, 32)           1280000   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 500, 32)           8320      \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,706\n",
            "Trainable params: 1,296,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 69s 305ms/step - loss: 0.6219 - accuracy: 0.6800\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 58s 288ms/step - loss: 0.4812 - accuracy: 0.7713\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 58s 292ms/step - loss: 0.2338 - accuracy: 0.9115\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 58s 288ms/step - loss: 0.0961 - accuracy: 0.9683\n",
            "Accuracy:  53.50000262260437\n"
          ]
        }
      ],
      "source": [
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(40000,embedding_vector_length,input_length = 500))\n",
        "model.add(LSTM(32,dropout=0.2, return_sequences = True ))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(2,activation = 'softmax'))\n",
        "model.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train,y_train, epochs = 4 , batch_size=23)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing the top models on the Wikipedia-CNN Dataset"
      ],
      "metadata": {
        "id": "F9-JBlAKtEm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/gitCorpus.csv')"
      ],
      "metadata": {
        "id": "Z2pfQTul3tMl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data"
      ],
      "metadata": {
        "id": "MEwMuOYh4Goo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train = Tokenizer('/content/gdrive/MyDrive/GCDC_rerelease/gitCorpus.csv')\n"
      ],
      "metadata": {
        "id": "4ROp4kua4r73"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train.data = new_train.data.drop(['label','to_be_replaced','train','file_id','replace_with','sen_position'],axis = 1)\n",
        "new_train.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "5F6i1osu8giB",
        "outputId": "f84053e0-29df-4629-de48-16f869270678"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      ctx  \\\n",
              "0       Estramustine (INN, USAN, BAN) (brand names Emc...   \n",
              "1       L² Puppis (also known as HD 56096) is a giant ...   \n",
              "2       David John (Davy/Davey) Gunn (1887-1955) was a...   \n",
              "3       Olivia Hussey (born Olivia Osuna; 17 April 195...   \n",
              "4       Tailapa II, or Taila, (r.973–997 CE) (or Ahava...   \n",
              "...                                                   ...   \n",
              "179079  -LRB- CNN -RRB- If you listen to rock or pop, ...   \n",
              "179080  -LRB- CNN -RRB- -- Pirates have struck again, ...   \n",
              "179081  -LRB- CNN -RRB- -- Russia will begin the const...   \n",
              "179082  -LRB- CNN -RRB- -- The man police say kidnappe...   \n",
              "179083  -LRB- CNN -RRB- -- Frostbite has forced Britis...   \n",
              "\n",
              "                                             ctx-replaced  \n",
              "0       Estramustine (INN, USAN, BAN) (brand names Emc...  \n",
              "1       L² Puppis (also known as HD 56096) is a giant ...  \n",
              "2       David John (Davy/Davey) Gunn (1887-1955) was a...  \n",
              "3       Olivia Hussey (born Olivia Osuna; 17 April 195...  \n",
              "4       Tailapa II, or Taila, (r.973–997 CE) (or Ahava...  \n",
              "...                                                   ...  \n",
              "179079                                                NaN  \n",
              "179080                                                NaN  \n",
              "179081                                                NaN  \n",
              "179082                                                NaN  \n",
              "179083                                                NaN  \n",
              "\n",
              "[179084 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a963716b-7947-4d76-88e6-7e97a012469a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ctx</th>\n",
              "      <th>ctx-replaced</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Estramustine (INN, USAN, BAN) (brand names Emc...</td>\n",
              "      <td>Estramustine (INN, USAN, BAN) (brand names Emc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L² Puppis (also known as HD 56096) is a giant ...</td>\n",
              "      <td>L² Puppis (also known as HD 56096) is a giant ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>David John (Davy/Davey) Gunn (1887-1955) was a...</td>\n",
              "      <td>David John (Davy/Davey) Gunn (1887-1955) was a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Olivia Hussey (born Olivia Osuna; 17 April 195...</td>\n",
              "      <td>Olivia Hussey (born Olivia Osuna; 17 April 195...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tailapa II, or Taila, (r.973–997 CE) (or Ahava...</td>\n",
              "      <td>Tailapa II, or Taila, (r.973–997 CE) (or Ahava...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179079</th>\n",
              "      <td>-LRB- CNN -RRB- If you listen to rock or pop, ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179080</th>\n",
              "      <td>-LRB- CNN -RRB- -- Pirates have struck again, ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179081</th>\n",
              "      <td>-LRB- CNN -RRB- -- Russia will begin the const...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179082</th>\n",
              "      <td>-LRB- CNN -RRB- -- The man police say kidnappe...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179083</th>\n",
              "      <td>-LRB- CNN -RRB- -- Frostbite has forced Britis...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>179084 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a963716b-7947-4d76-88e6-7e97a012469a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a963716b-7947-4d76-88e6-7e97a012469a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a963716b-7947-4d76-88e6-7e97a012469a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_data = new_train.data[['ctx']].copy()\n",
        "label = [1]*len(pos_data)\n",
        "pos_data = pos_data.rename(columns = {'ctx':'text'})\n",
        "pos_data['label']=label\n",
        "pos_data\n",
        "neg_data = new_train.data[['ctx-replaced']].copy()\n",
        "neg_data = neg_data.rename(columns = {'ctx-replaced':'text'})\n",
        "# neg_data = neg_data[neg_data['text'] != '' and neg_data['text' != None]]\n",
        "neg_data = neg_data.dropna()\n",
        "label = [0]*len(neg_data)\n",
        "neg_data['label'] = label\n",
        "neg_data\n",
        "new_train.data = pd.concat([pos_data,neg_data])\n",
        "new_train.data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "cCLOSXSf9nuI",
        "outputId": "8547b811-51ba-4da3-a19d-1ee3959f55a4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  label\n",
              "0       Estramustine (INN, USAN, BAN) (brand names Emc...      1\n",
              "1       L² Puppis (also known as HD 56096) is a giant ...      1\n",
              "2       David John (Davy/Davey) Gunn (1887-1955) was a...      1\n",
              "3       Olivia Hussey (born Olivia Osuna; 17 April 195...      1\n",
              "4       Tailapa II, or Taila, (r.973–997 CE) (or Ahava...      1\n",
              "...                                                   ...    ...\n",
              "142301  -LRB- Fast Company -RRB- -- For years,  employ...      0\n",
              "142302  Paris -LRB- CNN -RRB- -- France will start wit...      0\n",
              "142303  -LRB- CNN -RRB- -- Pinterest is the breakout s...      0\n",
              "142304  New York -LRB- CNN -RRB- -- Officer Rafael Ram...      0\n",
              "142305  -LRB- CNN -RRB- Would a taste of the finest Sw...      0\n",
              "\n",
              "[264347 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d98d7ce9-1a16-4c54-a862-b7cf48a3c112\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Estramustine (INN, USAN, BAN) (brand names Emc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L² Puppis (also known as HD 56096) is a giant ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>David John (Davy/Davey) Gunn (1887-1955) was a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Olivia Hussey (born Olivia Osuna; 17 April 195...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tailapa II, or Taila, (r.973–997 CE) (or Ahava...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142301</th>\n",
              "      <td>-LRB- Fast Company -RRB- -- For years,  employ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142302</th>\n",
              "      <td>Paris -LRB- CNN -RRB- -- France will start wit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142303</th>\n",
              "      <td>-LRB- CNN -RRB- -- Pinterest is the breakout s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142304</th>\n",
              "      <td>New York -LRB- CNN -RRB- -- Officer Rafael Ram...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142305</th>\n",
              "      <td>-LRB- CNN -RRB- Would a taste of the finest Sw...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>264347 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d98d7ce9-1a16-4c54-a862-b7cf48a3c112')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d98d7ce9-1a16-4c54-a862-b7cf48a3c112 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d98d7ce9-1a16-4c54-a862-b7cf48a3c112');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_train_mapping, inv_new_train_mapping = new_train.preprocess()\n",
        "new_train.data['encoding'] = new_train_mapping\n",
        "\n",
        "new_train.data = similarity_paragraph(new_train.data)\n"
      ],
      "metadata": {
        "id": "5jBnsY1s_xSr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = new_train.data.sample(frac = 0.8, random_state=200)\n",
        "test_split = new_train.data.drop(train_split.index)\n",
        "\n"
      ],
      "metadata": {
        "id": "TNBZadqGGnU6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "FRuN868FHAew",
        "outputId": "355a9f36-d453-4359-cb27-0185a79161a4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  label  \\\n",
              "157493  -LRB- CNN -RRB- -- World football 's governing...      1   \n",
              "61962   Turrilitidae  is a family of extinct heteromor...      1   \n",
              "94326   Digidogheadlock is the eighth album by Japanes...      1   \n",
              "118888  London,  England -LRB- CNN -RRB- -- The Britis...      1   \n",
              "154898  -LRB- CNN -RRB- -- Inside the Charles Manson r...      1   \n",
              "...                                                   ...    ...   \n",
              "108315  -LRB- CNN -RRB- -- Nurse Kaci Hickox and her b...      1   \n",
              "131663  Cairo,  Egypt -LRB- CNN -RRB- -- Authorities i...      1   \n",
              "155532  -LRB- CNN -RRB- -- Pontiac lovers are feeling ...      1   \n",
              "115363  Russian Prime Minister Dmitry Medvedev has sig...      1   \n",
              "29155   The Jennie Foley Building, also known as the J...      1   \n",
              "\n",
              "                                           sentences_list  \\\n",
              "157493  [-LRB- CNN -RRB- -- World football 's governin...   \n",
              "61962   [Turrilitidae  is a family of extinct heteromo...   \n",
              "94326   [Digidogheadlock is the eighth album by Japane...   \n",
              "118888  [London,  England -LRB- CNN -RRB- -- The Briti...   \n",
              "154898  [-LRB- CNN -RRB- -- Inside the Charles Manson ...   \n",
              "...                                                   ...   \n",
              "108315  [-LRB- CNN -RRB- -- Nurse Kaci Hickox and her ...   \n",
              "131663  [Cairo,  Egypt -LRB- CNN -RRB- -- Authorities ...   \n",
              "155532  [-LRB- CNN -RRB- -- Pontiac lovers are feeling...   \n",
              "115363  [Russian Prime Minister Dmitry Medvedev has si...   \n",
              "29155   [The Jennie Foley Building, also known as the ...   \n",
              "\n",
              "                                                 encoding  similarity  \n",
              "157493  [30, 31, 32, 27, 137, 227, 15, 3497, 447, 2491...    0.100000  \n",
              "61962   [337218, 6, 10, 8, 151, 4, 3604, 337219, 26839...    0.000000  \n",
              "94326   [394473, 10, 2, 2980, 105, 21, 643, 207, 12, 8...    0.091287  \n",
              "118888  [282, 1, 6, 279, 30, 31, 32, 27, 12, 189, 2699...    0.000000  \n",
              "154898  [30, 31, 32, 27, 6245, 2, 966, 12012, 1312, 26...    0.109109  \n",
              "...                                                   ...         ...  \n",
              "108315  [30, 31, 32, 27, 20800, 52617, 34480, 5, 57, 5...    0.108465  \n",
              "131663  [2850, 1, 6, 1261, 30, 31, 32, 27, 2114, 7, 12...    0.120386  \n",
              "155532  [30, 31, 32, 27, 20349, 9075, 35, 3812, 28369,...    0.070014  \n",
              "115363  [555, 949, 483, 14132, 13378, 33, 920, 8, 9333...    0.000000  \n",
              "29155   [12, 30671, 13311, 2840, 1, 48, 65, 18, 2, 306...    0.000000  \n",
              "\n",
              "[211478 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7be9eeba-5921-4a31-817a-e695adb92b52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sentences_list</th>\n",
              "      <th>encoding</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>157493</th>\n",
              "      <td>-LRB- CNN -RRB- -- World football 's governing...</td>\n",
              "      <td>1</td>\n",
              "      <td>[-LRB- CNN -RRB- -- World football 's governin...</td>\n",
              "      <td>[30, 31, 32, 27, 137, 227, 15, 3497, 447, 2491...</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61962</th>\n",
              "      <td>Turrilitidae  is a family of extinct heteromor...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Turrilitidae  is a family of extinct heteromo...</td>\n",
              "      <td>[337218, 6, 10, 8, 151, 4, 3604, 337219, 26839...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94326</th>\n",
              "      <td>Digidogheadlock is the eighth album by Japanes...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Digidogheadlock is the eighth album by Japane...</td>\n",
              "      <td>[394473, 10, 2, 2980, 105, 21, 643, 207, 12, 8...</td>\n",
              "      <td>0.091287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118888</th>\n",
              "      <td>London,  England -LRB- CNN -RRB- -- The Britis...</td>\n",
              "      <td>1</td>\n",
              "      <td>[London,  England -LRB- CNN -RRB- -- The Briti...</td>\n",
              "      <td>[282, 1, 6, 279, 30, 31, 32, 27, 12, 189, 2699...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154898</th>\n",
              "      <td>-LRB- CNN -RRB- -- Inside the Charles Manson r...</td>\n",
              "      <td>1</td>\n",
              "      <td>[-LRB- CNN -RRB- -- Inside the Charles Manson ...</td>\n",
              "      <td>[30, 31, 32, 27, 6245, 2, 966, 12012, 1312, 26...</td>\n",
              "      <td>0.109109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108315</th>\n",
              "      <td>-LRB- CNN -RRB- -- Nurse Kaci Hickox and her b...</td>\n",
              "      <td>1</td>\n",
              "      <td>[-LRB- CNN -RRB- -- Nurse Kaci Hickox and her ...</td>\n",
              "      <td>[30, 31, 32, 27, 20800, 52617, 34480, 5, 57, 5...</td>\n",
              "      <td>0.108465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131663</th>\n",
              "      <td>Cairo,  Egypt -LRB- CNN -RRB- -- Authorities i...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Cairo,  Egypt -LRB- CNN -RRB- -- Authorities ...</td>\n",
              "      <td>[2850, 1, 6, 1261, 30, 31, 32, 27, 2114, 7, 12...</td>\n",
              "      <td>0.120386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155532</th>\n",
              "      <td>-LRB- CNN -RRB- -- Pontiac lovers are feeling ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[-LRB- CNN -RRB- -- Pontiac lovers are feeling...</td>\n",
              "      <td>[30, 31, 32, 27, 20349, 9075, 35, 3812, 28369,...</td>\n",
              "      <td>0.070014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115363</th>\n",
              "      <td>Russian Prime Minister Dmitry Medvedev has sig...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Russian Prime Minister Dmitry Medvedev has si...</td>\n",
              "      <td>[555, 949, 483, 14132, 13378, 33, 920, 8, 9333...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29155</th>\n",
              "      <td>The Jennie Foley Building, also known as the J...</td>\n",
              "      <td>1</td>\n",
              "      <td>[The Jennie Foley Building, also known as the ...</td>\n",
              "      <td>[12, 30671, 13311, 2840, 1, 48, 65, 18, 2, 306...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>211478 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7be9eeba-5921-4a31-817a-e695adb92b52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7be9eeba-5921-4a31-817a-e695adb92b52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7be9eeba-5921-4a31-817a-e695adb92b52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "EgY24mirHBdz",
        "outputId": "4a6f8cd6-f76c-4320-9d06-20f29dbe2228"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  label  \\\n",
              "33      The swimming competitions at the 2016 Summer O...      1   \n",
              "56      The Orlando Shakespeare Theater is a theater c...      1   \n",
              "67      Histocompatibility, or tissue compatibility, i...      1   \n",
              "86      William Morris (January 1, 1861 – January 11, ...      1   \n",
              "97      Alphonse Areola (born 27 February 1993) is a F...      1   \n",
              "...                                                   ...    ...   \n",
              "142202  Tokyo -LRB- CNN -RRB- -- Japanese Prime Minist...      0   \n",
              "142231  -LRB- CNN -RRB- -- With a first name that mean...      0   \n",
              "142269  -LRB- CNN -RRB- -- As about 2 % of babies born...      0   \n",
              "142302  Paris -LRB- CNN -RRB- -- France will start wit...      0   \n",
              "142304  New York -LRB- CNN -RRB- -- Officer Rafael Ram...      0   \n",
              "\n",
              "                                           sentences_list  \\\n",
              "33      [The swimming competitions at the 2016 Summer ...   \n",
              "56      [The Orlando Shakespeare Theater is a theater ...   \n",
              "67      [Histocompatibility, or tissue compatibility, ...   \n",
              "86      [William Morris (January 1, 1861 – January 11,...   \n",
              "97      [Alphonse Areola (born 27 February 1993) is a ...   \n",
              "...                                                   ...   \n",
              "142202  [Tokyo -LRB- CNN -RRB- -- Japanese Prime Minis...   \n",
              "142231  [-LRB- CNN -RRB- -- With a first name that mea...   \n",
              "142269  [-LRB- CNN -RRB- -- As about 2 % of babies bor...   \n",
              "142302  [Paris -LRB- CNN -RRB- -- France will start wi...   \n",
              "142304  [New York -LRB- CNN -RRB- -- Officer Rafael Ra...   \n",
              "\n",
              "                                                 encoding  similarity  \n",
              "33      [12, 4239, 4005, 26, 2, 441, 1786, 1244, 7, 27...    0.157135  \n",
              "56      [12, 4408, 6544, 5467, 10, 8, 2773, 174, 149, ...    0.077152  \n",
              "67      [126974, 1, 42, 5326, 22566, 1, 10, 2, 1173, 4...    0.000000  \n",
              "86      [647, 5238, 20, 246, 160, 1, 6907, 179, 246, 4...    0.000000  \n",
              "97      [26818, 126992, 20, 96, 788, 328, 1122, 19, 10...    0.000000  \n",
              "...                                                   ...         ...  \n",
              "142202  [2162, 30, 31, 32, 27, 643, 949, 483, 34468, 1...    0.000000  \n",
              "142231  [30, 31, 32, 27, 624, 8, 50, 124, 23, 793, 14,...    0.133333  \n",
              "142269  [30, 31, 32, 27, 218, 67, 204, 337, 4, 7112, 9...    0.055048  \n",
              "142302  [926, 30, 31, 32, 27, 503, 68, 764, 14857, 980...    0.000000  \n",
              "142304  [69, 128, 30, 31, 32, 27, 3057, 4164, 10536, 4...    0.000000  \n",
              "\n",
              "[25516 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe796add-42d2-4699-898c-1010eb3a9134\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>sentences_list</th>\n",
              "      <th>encoding</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>The swimming competitions at the 2016 Summer O...</td>\n",
              "      <td>1</td>\n",
              "      <td>[The swimming competitions at the 2016 Summer ...</td>\n",
              "      <td>[12, 4239, 4005, 26, 2, 441, 1786, 1244, 7, 27...</td>\n",
              "      <td>0.157135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>The Orlando Shakespeare Theater is a theater c...</td>\n",
              "      <td>1</td>\n",
              "      <td>[The Orlando Shakespeare Theater is a theater ...</td>\n",
              "      <td>[12, 4408, 6544, 5467, 10, 8, 2773, 174, 149, ...</td>\n",
              "      <td>0.077152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>Histocompatibility, or tissue compatibility, i...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Histocompatibility, or tissue compatibility, ...</td>\n",
              "      <td>[126974, 1, 42, 5326, 22566, 1, 10, 2, 1173, 4...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>William Morris (January 1, 1861 – January 11, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[William Morris (January 1, 1861 – January 11,...</td>\n",
              "      <td>[647, 5238, 20, 246, 160, 1, 6907, 179, 246, 4...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Alphonse Areola (born 27 February 1993) is a F...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Alphonse Areola (born 27 February 1993) is a ...</td>\n",
              "      <td>[26818, 126992, 20, 96, 788, 328, 1122, 19, 10...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142202</th>\n",
              "      <td>Tokyo -LRB- CNN -RRB- -- Japanese Prime Minist...</td>\n",
              "      <td>0</td>\n",
              "      <td>[Tokyo -LRB- CNN -RRB- -- Japanese Prime Minis...</td>\n",
              "      <td>[2162, 30, 31, 32, 27, 643, 949, 483, 34468, 1...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142231</th>\n",
              "      <td>-LRB- CNN -RRB- -- With a first name that mean...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-LRB- CNN -RRB- -- With a first name that mea...</td>\n",
              "      <td>[30, 31, 32, 27, 624, 8, 50, 124, 23, 793, 14,...</td>\n",
              "      <td>0.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142269</th>\n",
              "      <td>-LRB- CNN -RRB- -- As about 2 % of babies born...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-LRB- CNN -RRB- -- As about 2 % of babies bor...</td>\n",
              "      <td>[30, 31, 32, 27, 218, 67, 204, 337, 4, 7112, 9...</td>\n",
              "      <td>0.055048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142302</th>\n",
              "      <td>Paris -LRB- CNN -RRB- -- France will start wit...</td>\n",
              "      <td>0</td>\n",
              "      <td>[Paris -LRB- CNN -RRB- -- France will start wi...</td>\n",
              "      <td>[926, 30, 31, 32, 27, 503, 68, 764, 14857, 980...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142304</th>\n",
              "      <td>New York -LRB- CNN -RRB- -- Officer Rafael Ram...</td>\n",
              "      <td>0</td>\n",
              "      <td>[New York -LRB- CNN -RRB- -- Officer Rafael Ra...</td>\n",
              "      <td>[69, 128, 30, 31, 32, 27, 3057, 4164, 10536, 4...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25516 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe796add-42d2-4699-898c-1010eb3a9134')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe796add-42d2-4699-898c-1010eb3a9134 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe796add-42d2-4699-898c-1010eb3a9134');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_split.to_csv('/content/gdrive/MyDrive/GCDC_rerelease/train_split.csv')\n",
        "test_split.to_csv('/content/gdrive/MyDrive/GCDC_rerelease/test_split.csv')"
      ],
      "metadata": {
        "id": "PdjMzVJzPzIq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_split = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/train_split.csv')\n",
        "test_split = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/test_split.csv')\n",
        "\n",
        "# train_split = total_split.sample(frac = 0.9, random_state=200)\n",
        "# validation_split = total_split.drop(train_split.index)"
      ],
      "metadata": {
        "id": "BUw6bL48Rpxk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train_split['encoding'],maxlen = 500)\n",
        "y_train = train_split['label']\n",
        "y_train = tf.one_hot(y_train,depth = 2)\n",
        "X_test = sequence.pad_sequences(test_split['encoding'],maxlen=500)\n",
        "y_test = test_split['label']\n",
        "y_test = tf.one_hot(y_test,depth = 2)"
      ],
      "metadata": {
        "id": "yIAyjp45vWfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train_split['encoding'],maxlen = 500)\n",
        "y_train = train_split['label']\n",
        "y_train = tf.one_hot(y_train,depth = 2)\n",
        "X_test = sequence.pad_sequences(test_split['encoding'],maxlen=500)\n",
        "y_test = test_split['label']\n",
        "y_test = tf.one_hot(y_test,depth = 2)\n",
        "# val_x = sequence.pad_sequences(validation_split['encoding'],maxlen=500)\n",
        "# val_y = validation_split['label']\n",
        "# val_y = tf.one_hot(val_y, depth = 2)"
      ],
      "metadata": {
        "id": "LeLeG672Srbj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "2077f5a9-35d7-4ecf-a9f0-6cadde93842d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-e9ff12ae73c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m    152\u001b[0m   return sequence.pad_sequences(\n\u001b[1;32m    153\u001b[0m       \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m       padding=padding, truncating=truncating, value=value)\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m keras_export(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '3, 9, 574, 284, 26, 2, 1167, 31312, 1902, 3, 12, 668, 11, 405, 6572, 68, 43, 230, 17, 422, 5, 548, 284, 7, 1556, 22735, 3, 12, 1252, 16, 668, 11, 405, 677, 10, 8, 857, 4, 3237, 16, 3153, 121, 2772, 4"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification with 30 epochs"
      ],
      "metadata": {
        "id": "fhV3p-MrOnWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(40000,embedding_vector_length,input_length = 500))\n",
        "model.add(LSTM(32,dropout=0.2, return_sequences = True ))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(2,activation = 'softmax'))\n",
        "model.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='/content/gdrive/MyDrive/GCDC_rerelease/checkpoints', save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)\n",
        "print(model.summary())\n",
        "model.fit(X_train,y_train, epochs = 30, batch_size=500,callbacks = [model_checkpoint_callback])\n",
        "scores = model.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiw4JFOnSzOH",
        "outputId": "6ee09fcd-20fb-4fae-8c1f-7f5c0162e292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 500, 32)           1280000   \n",
            "                                                                 \n",
            " lstm_18 (LSTM)              (None, 500, 32)           8320      \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,706\n",
            "Trainable params: 1,296,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "422/423 [============================>.] - ETA: 0s - loss: 0.6311 - accuracy: 0.6766WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 25s 51ms/step - loss: 0.6310 - accuracy: 0.6767\n",
            "Epoch 2/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.6259 - accuracy: 0.6769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 23s 54ms/step - loss: 0.6259 - accuracy: 0.6769\n",
            "Epoch 3/30\n",
            "422/423 [============================>.] - ETA: 0s - loss: 0.6151 - accuracy: 0.6772WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 52ms/step - loss: 0.6152 - accuracy: 0.6771\n",
            "Epoch 4/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.6065 - accuracy: 0.6788WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 51ms/step - loss: 0.6065 - accuracy: 0.6788\n",
            "Epoch 5/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.5901 - accuracy: 0.6837WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 52ms/step - loss: 0.5901 - accuracy: 0.6837\n",
            "Epoch 6/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.5721 - accuracy: 0.6901WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 52ms/step - loss: 0.5721 - accuracy: 0.6901\n",
            "Epoch 7/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.5532 - accuracy: 0.6981WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 23s 54ms/step - loss: 0.5532 - accuracy: 0.6981\n",
            "Epoch 8/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.5361 - accuracy: 0.7042WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 52ms/step - loss: 0.5361 - accuracy: 0.7042\n",
            "Epoch 9/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.7105WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.5203 - accuracy: 0.7105\n",
            "Epoch 10/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.5070 - accuracy: 0.7172WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.5070 - accuracy: 0.7172\n",
            "Epoch 11/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.4944 - accuracy: 0.7224WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.4944 - accuracy: 0.7224\n",
            "Epoch 12/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.7272WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.4785 - accuracy: 0.7272\n",
            "Epoch 13/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.7332WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.4663 - accuracy: 0.7332\n",
            "Epoch 14/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.7368WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.4547 - accuracy: 0.7368\n",
            "Epoch 15/30\n",
            "422/423 [============================>.] - ETA: 0s - loss: 0.4445 - accuracy: 0.7421WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.4445 - accuracy: 0.7421\n",
            "Epoch 16/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.7454WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 52ms/step - loss: 0.4365 - accuracy: 0.7454\n",
            "Epoch 17/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.7498WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.4274 - accuracy: 0.7498\n",
            "Epoch 18/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.4202 - accuracy: 0.7526WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.4202 - accuracy: 0.7526\n",
            "Epoch 19/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.7572WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.4132 - accuracy: 0.7572\n",
            "Epoch 20/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.7615WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.4055 - accuracy: 0.7615\n",
            "Epoch 21/30\n",
            "422/423 [============================>.] - ETA: 0s - loss: 0.4003 - accuracy: 0.7655WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.4003 - accuracy: 0.7655\n",
            "Epoch 22/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.7692WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.3938 - accuracy: 0.7692\n",
            "Epoch 23/30\n",
            "422/423 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.7744WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.3870 - accuracy: 0.7744\n",
            "Epoch 24/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.7776WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.3815 - accuracy: 0.7776\n",
            "Epoch 25/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.7805WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.3756 - accuracy: 0.7805\n",
            "Epoch 26/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.7853WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.3699 - accuracy: 0.7853\n",
            "Epoch 27/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.3654 - accuracy: 0.7890WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.3654 - accuracy: 0.7890\n",
            "Epoch 28/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.7933WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.3597 - accuracy: 0.7933\n",
            "Epoch 29/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.3555 - accuracy: 0.7958WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.3555 - accuracy: 0.7958\n",
            "Epoch 30/30\n",
            "423/423 [==============================] - ETA: 0s - loss: 0.3500 - accuracy: 0.8005WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "423/423 [==============================] - 22s 53ms/step - loss: 0.3500 - accuracy: 0.8005\n",
            "Accuracy:  68.89402866363525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification with 20 Epochs"
      ],
      "metadata": {
        "id": "OCl6XymVOvyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(40000,embedding_vector_length,input_length = 500))\n",
        "model.add(LSTM(32,dropout=0.2, return_sequences = True ))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(2,activation = 'softmax'))\n",
        "model.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='/content/gdrive/MyDrive/GCDC_rerelease/checkpoints', save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)\n",
        "print(model.summary())\n",
        "model.fit(X_train,y_train, epochs = 20, batch_size=82,callbacks = [model_checkpoint_callback])\n",
        "scores = model.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwcGPETjd790",
        "outputId": "8a750bab-c948-40f5-9b31-6be09fec8d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 500, 32)           1280000   \n",
            "                                                                 \n",
            " lstm_20 (LSTM)              (None, 500, 32)           8320      \n",
            "                                                                 \n",
            " lstm_21 (LSTM)              (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,706\n",
            "Trainable params: 1,296,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "2578/2579 [============================>.] - ETA: 0s - loss: 0.6299 - accuracy: 0.6769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 87s 31ms/step - loss: 0.6299 - accuracy: 0.6768\n",
            "Epoch 2/20\n",
            "2579/2579 [==============================] - ETA: 0s - loss: 0.6234 - accuracy: 0.6769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 31ms/step - loss: 0.6234 - accuracy: 0.6769\n",
            "Epoch 3/20\n",
            "2579/2579 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.6769WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 31ms/step - loss: 0.6217 - accuracy: 0.6769\n",
            "Epoch 4/20\n",
            "2579/2579 [==============================] - ETA: 0s - loss: 0.6066 - accuracy: 0.6783WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 31ms/step - loss: 0.6066 - accuracy: 0.6783\n",
            "Epoch 5/20\n",
            "2579/2579 [==============================] - ETA: 0s - loss: 0.5946 - accuracy: 0.6826WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 82s 32ms/step - loss: 0.5946 - accuracy: 0.6826\n",
            "Epoch 6/20\n",
            "2578/2579 [============================>.] - ETA: 0s - loss: 0.5756 - accuracy: 0.6898WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 31ms/step - loss: 0.5756 - accuracy: 0.6898\n",
            "Epoch 7/20\n",
            "2578/2579 [============================>.] - ETA: 0s - loss: 0.5668 - accuracy: 0.6952WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 32ms/step - loss: 0.5668 - accuracy: 0.6952\n",
            "Epoch 8/20\n",
            "2578/2579 [============================>.] - ETA: 0s - loss: 0.5418 - accuracy: 0.7061WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 31ms/step - loss: 0.5418 - accuracy: 0.7060\n",
            "Epoch 9/20\n",
            "2578/2579 [============================>.] - ETA: 0s - loss: 0.5253 - accuracy: 0.7130WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 32ms/step - loss: 0.5253 - accuracy: 0.7129\n",
            "Epoch 10/20\n",
            "2578/2579 [============================>.] - ETA: 0s - loss: 0.5080 - accuracy: 0.7201WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 32ms/step - loss: 0.5080 - accuracy: 0.7201\n",
            "Epoch 11/20\n",
            "2579/2579 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.7076WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 82s 32ms/step - loss: 0.5372 - accuracy: 0.7076\n",
            "Epoch 12/20\n",
            "2579/2579 [==============================] - ETA: 0s - loss: 0.4939 - accuracy: 0.7272WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 82s 32ms/step - loss: 0.4939 - accuracy: 0.7272\n",
            "Epoch 13/20\n",
            "2579/2579 [==============================] - ETA: 0s - loss: 0.4770 - accuracy: 0.7338WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 32ms/step - loss: 0.4770 - accuracy: 0.7338\n",
            "Epoch 14/20\n",
            "2579/2579 [==============================] - ETA: 0s - loss: 0.4626 - accuracy: 0.7406WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 32ms/step - loss: 0.4626 - accuracy: 0.7406\n",
            "Epoch 15/20\n",
            "2578/2579 [============================>.] - ETA: 0s - loss: 0.4510 - accuracy: 0.7464WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 32ms/step - loss: 0.4510 - accuracy: 0.7464\n",
            "Epoch 16/20\n",
            "2578/2579 [============================>.] - ETA: 0s - loss: 0.4392 - accuracy: 0.7530WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 32ms/step - loss: 0.4392 - accuracy: 0.7530\n",
            "Epoch 17/20\n",
            "2579/2579 [==============================] - ETA: 0s - loss: 0.4286 - accuracy: 0.7585WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 32ms/step - loss: 0.4286 - accuracy: 0.7585\n",
            "Epoch 18/20\n",
            "2579/2579 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.7648WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 32ms/step - loss: 0.4173 - accuracy: 0.7648\n",
            "Epoch 19/20\n",
            "2579/2579 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 0.7720WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 81s 31ms/step - loss: 0.4079 - accuracy: 0.7720\n",
            "Epoch 20/20\n",
            "2578/2579 [============================>.] - ETA: 0s - loss: 0.3983 - accuracy: 0.7775WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "2579/2579 [==============================] - 82s 32ms/step - loss: 0.3983 - accuracy: 0.7775\n",
            "Accuracy:  71.66091799736023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/gdrive/MyDrive/GCDC_rerelease/new_data_lstm_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ2VvP_SkqOS",
        "outputId": "a16fe654-2518-47c8-fa9c-ad675c978ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses, lstm_cell_21_layer_call_fn, lstm_cell_21_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/GCDC_rerelease/new_data_lstm_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/GCDC_rerelease/new_data_lstm_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f23ea4c8a50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f23ea4cdcd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification with Minimum Similarity Function"
      ],
      "metadata": {
        "id": "4Dgh3zQCO1wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train_split['encoding'],maxlen = 500)\n",
        "y_train = train_split['label']\n",
        "y_train = tf.one_hot(y_train,depth = 2)\n",
        "X_test = sequence.pad_sequences(test_split['encoding'],maxlen=500)\n",
        "y_test = test_split['label']\n",
        "y_test = tf.one_hot(y_test,depth = 2)\n",
        "\n",
        "val_x = sequence.pad_sequences(validation_split['encoding'],maxlen=500)\n",
        "val_y = validation_split['label']\n",
        "val_y = tf.one_hot(val_y, depth = 2)\n",
        "\n",
        "\n",
        "X_train = np.append(train_split['similarity'][:,np.newaxis], X_train, axis=1)\n",
        "X_test = np.append(test_split['similarity'][:,np.newaxis],X_test, axis=1)\n",
        "\n",
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(400000,embedding_vector_length,input_length = 501))\n",
        "model.add(LSTM(32,dropout=0.2, return_sequences = True ))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(2,activation = 'softmax'))\n",
        "model.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='/content/gdrive/MyDrive/GCDC_rerelease/checkpoints', save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)\n",
        "\n",
        "print(model.summary())\n",
        "model.fit(X_train,y_train, epochs = 20 , batch_size=82,validation_data = (val_x,val_y), callbacks = model_checkpoint_callback)\n",
        "# model.fit(X_train,y_train, epochs = 20 , batch_size=82)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WjvwxW74lBdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison of Test Data in GCDC Corpus"
      ],
      "metadata": {
        "id": "yzOUbZC5JPLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Clinton_train.csv')\n",
        "data2 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Yahoo_train.csv')\n",
        "data3 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Yelp_train.csv')\n",
        "data4 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Enron_train.csv')\n",
        "\n",
        "data5 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Yahoo_test.csv')\n",
        "data6 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Yelp_test.csv')\n",
        "data7 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Enron_test.csv')\n",
        "data8 = pd.read_csv('/content/gdrive/MyDrive/GCDC_rerelease/Clinton_test.csv')"
      ],
      "metadata": {
        "id": "kQEwChce5-nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_t = pd.concat([data1,data2,data3,data4,data5,data6,data7])\n",
        "\n",
        "data_t.to_csv('/content/gdrive/MyDrive/GCDC_rerelease/temp_train.csv')\n"
      ],
      "metadata": {
        "id": "KmdBJzPvBwXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = Tokenizer('/content/gdrive/MyDrive/GCDC_rerelease/temp_train.csv')\n",
        "test = Tokenizer(\"/content/gdrive/MyDrive/GCDC_rerelease/Clinton_test.csv\")"
      ],
      "metadata": {
        "id": "MIpCnUvTDIO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = array(train.data['labelA'])\n",
        "encoded = to_categorical(lst)\n",
        "lst = array(test.data['labelA'])\n",
        "t_encoded = to_categorical(lst)\n",
        "\n",
        "train_mapping, inv_train_mapping = train.preprocess()\n",
        "test_mapping, inv_test_mapping = test.preprocess()"
      ],
      "metadata": {
        "id": "dQXeCNRbE3iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.data = similarity_paragraph(train.data)\n",
        "test.data = similarity_paragraph(test.data)\n",
        "\n",
        "train.data['encoding'] = train_mapping\n",
        "test.data['encoding'] = test_mapping"
      ],
      "metadata": {
        "id": "nZtJkFXFFIgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coh_bin = []\n",
        "for i in range(4600):\n",
        "  if train.data['labelA'].tolist()[i] >=2:\n",
        "    coh_bin.append(1)\n",
        "  else:\n",
        "    coh_bin.append(0)\n",
        "train.data['bin_coh']= coh_bin\n",
        "\n",
        "\n",
        "coh_bin=[]\n",
        "for i in range(200):\n",
        "  if test.data['labelA'].tolist()[i] >=2:\n",
        "    coh_bin.append(1)\n",
        "  else:\n",
        "    coh_bin.append(0)\n",
        "\n",
        "test.data['bin_coh']=coh_bin"
      ],
      "metadata": {
        "id": "U6Cs-vkHFTz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = array(train.data['bin_coh'])\n",
        "encoded = to_categorical(lst)\n",
        "\n",
        "lst = array(test.data['bin_coh'])\n",
        "t_encoded = to_categorical(lst)\n"
      ],
      "metadata": {
        "id": "QIpK2ZqZFhCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train.data['encoding'],maxlen = 500)\n",
        "y_train = encoded#train.data['h_e']\n",
        "X_test = sequence.pad_sequences(test.data['encoding'],maxlen=500)\n",
        "y_test = t_encoded#test.data['h_e']\n",
        "\n",
        "X_train = np.append(train.data['similarity'][:,np.newaxis], X_train, axis=1)\n",
        "X_test = np.append(test.data['similarity'][:,np.newaxis],X_test, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilg-wXyIFqKc",
        "outputId": "b9b095af-13fa-41c2-d295-6531b334a24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clinton Test Data"
      ],
      "metadata": {
        "id": "nivUA1gdN6FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Clinton_Test_Data\n",
        "\n",
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(40000,embedding_vector_length,input_length = 501))\n",
        "model.add(LSTM(32,dropout=0.2, return_sequences = True ))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(2,activation = 'softmax'))\n",
        "model.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train,y_train, epochs = 15 , batch_size=23)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cfe6ZhCXGrEp",
        "outputId": "5e811366-99bb-4280-f509-87fd0dc02460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 501, 32)           1280000   \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 501, 32)           8320      \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,706\n",
            "Trainable params: 1,296,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "200/200 [==============================] - 59s 278ms/step - loss: 0.6255 - accuracy: 0.6757\n",
            "Epoch 2/15\n",
            "200/200 [==============================] - 58s 292ms/step - loss: 0.4898 - accuracy: 0.7650\n",
            "Epoch 3/15\n",
            "200/200 [==============================] - 55s 277ms/step - loss: 0.2682 - accuracy: 0.8970\n",
            "Epoch 4/15\n",
            "200/200 [==============================] - 55s 275ms/step - loss: 0.1276 - accuracy: 0.9598\n",
            "Epoch 5/15\n",
            "200/200 [==============================] - 55s 277ms/step - loss: 0.0638 - accuracy: 0.9815\n",
            "Epoch 6/15\n",
            "200/200 [==============================] - 55s 276ms/step - loss: 0.0369 - accuracy: 0.9907\n",
            "Epoch 7/15\n",
            "200/200 [==============================] - 55s 276ms/step - loss: 0.0264 - accuracy: 0.9935\n",
            "Epoch 8/15\n",
            "200/200 [==============================] - 55s 276ms/step - loss: 0.0220 - accuracy: 0.9943\n",
            "Epoch 9/15\n",
            "200/200 [==============================] - 55s 277ms/step - loss: 0.0234 - accuracy: 0.9928\n",
            "Epoch 10/15\n",
            "200/200 [==============================] - 56s 279ms/step - loss: 0.0207 - accuracy: 0.9957\n",
            "Epoch 11/15\n",
            "200/200 [==============================] - 56s 278ms/step - loss: 0.0248 - accuracy: 0.9939\n",
            "Epoch 12/15\n",
            "200/200 [==============================] - 55s 276ms/step - loss: 0.0197 - accuracy: 0.9963\n",
            "Epoch 13/15\n",
            "200/200 [==============================] - 55s 274ms/step - loss: 0.0157 - accuracy: 0.9970\n",
            "Epoch 14/15\n",
            "200/200 [==============================] - 55s 275ms/step - loss: 0.0159 - accuracy: 0.9965\n",
            "Epoch 15/15\n",
            "200/200 [==============================] - 55s 274ms/step - loss: 0.0148 - accuracy: 0.9965\n",
            "Accuracy:  61.000001430511475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enron Test Data"
      ],
      "metadata": {
        "id": "77J_RIR3N-JY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Enron_Test_Data\n",
        "\n",
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(40000,embedding_vector_length,input_length = 501))\n",
        "model.add(LSTM(32,dropout=0.2, return_sequences = True ))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(2,activation = 'softmax'))\n",
        "model.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train,y_train, epochs = 15 , batch_size=23)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RchSMAluGuEt",
        "outputId": "65f4b696-7e30-4752-9615-37a8636d6b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 501, 32)           1280000   \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 501, 32)           8320      \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,706\n",
            "Trainable params: 1,296,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "200/200 [==============================] - 64s 290ms/step - loss: 0.6288 - accuracy: 0.6763\n",
            "Epoch 2/15\n",
            "200/200 [==============================] - 56s 281ms/step - loss: 0.5036 - accuracy: 0.7589\n",
            "Epoch 3/15\n",
            "200/200 [==============================] - 55s 276ms/step - loss: 0.2686 - accuracy: 0.8922\n",
            "Epoch 4/15\n",
            "200/200 [==============================] - 55s 275ms/step - loss: 0.1295 - accuracy: 0.9530\n",
            "Epoch 5/15\n",
            "200/200 [==============================] - 55s 275ms/step - loss: 0.0619 - accuracy: 0.9817\n",
            "Epoch 6/15\n",
            "200/200 [==============================] - 55s 275ms/step - loss: 0.0343 - accuracy: 0.9913\n",
            "Epoch 7/15\n",
            "200/200 [==============================] - 56s 281ms/step - loss: 0.0319 - accuracy: 0.9922\n",
            "Epoch 8/15\n",
            "200/200 [==============================] - 55s 277ms/step - loss: 0.0243 - accuracy: 0.9941\n",
            "Epoch 9/15\n",
            "200/200 [==============================] - 72s 360ms/step - loss: 0.0193 - accuracy: 0.9952\n",
            "Epoch 10/15\n",
            "200/200 [==============================] - 56s 278ms/step - loss: 0.0190 - accuracy: 0.9959\n",
            "Epoch 11/15\n",
            "200/200 [==============================] - 55s 274ms/step - loss: 0.0181 - accuracy: 0.9954\n",
            "Epoch 12/15\n",
            "200/200 [==============================] - 56s 278ms/step - loss: 0.0188 - accuracy: 0.9948\n",
            "Epoch 13/15\n",
            "200/200 [==============================] - 55s 275ms/step - loss: 0.0192 - accuracy: 0.9948\n",
            "Epoch 14/15\n",
            "200/200 [==============================] - 55s 274ms/step - loss: 0.0154 - accuracy: 0.9963\n",
            "Epoch 15/15\n",
            "200/200 [==============================] - 54s 272ms/step - loss: 0.0136 - accuracy: 0.9974\n",
            "Accuracy:  66.00000262260437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yelp  Test Data"
      ],
      "metadata": {
        "id": "SITI4qm8OBVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Yelp_Test_Data\n",
        "\n",
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(40000,embedding_vector_length,input_length = 501))\n",
        "model.add(LSTM(32,dropout=0.2, return_sequences = True ))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(2,activation = 'softmax'))\n",
        "model.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train,y_train, epochs = 15 , batch_size=23)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7fdOW9pGkvc",
        "outputId": "9103c937-d920-496b-a801-e48cbc611c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 501, 32)           1280000   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 501, 32)           8320      \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,706\n",
            "Trainable params: 1,296,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "200/200 [==============================] - 58s 274ms/step - loss: 0.6219 - accuracy: 0.6743\n",
            "Epoch 2/15\n",
            "200/200 [==============================] - 56s 281ms/step - loss: 0.4534 - accuracy: 0.8026\n",
            "Epoch 3/15\n",
            "200/200 [==============================] - 55s 278ms/step - loss: 0.2300 - accuracy: 0.9133\n",
            "Epoch 4/15\n",
            "200/200 [==============================] - 55s 273ms/step - loss: 0.1124 - accuracy: 0.9641\n",
            "Epoch 5/15\n",
            "200/200 [==============================] - 55s 274ms/step - loss: 0.0668 - accuracy: 0.9809\n",
            "Epoch 6/15\n",
            "200/200 [==============================] - 55s 274ms/step - loss: 0.0418 - accuracy: 0.9893\n",
            "Epoch 7/15\n",
            "200/200 [==============================] - 54s 271ms/step - loss: 0.0278 - accuracy: 0.9937\n",
            "Epoch 8/15\n",
            "200/200 [==============================] - 54s 270ms/step - loss: 0.0326 - accuracy: 0.9917\n",
            "Epoch 9/15\n",
            "200/200 [==============================] - 54s 272ms/step - loss: 0.0208 - accuracy: 0.9963\n",
            "Epoch 10/15\n",
            "200/200 [==============================] - 54s 269ms/step - loss: 0.0241 - accuracy: 0.9952\n",
            "Epoch 11/15\n",
            "200/200 [==============================] - 55s 273ms/step - loss: 0.0318 - accuracy: 0.9926\n",
            "Epoch 12/15\n",
            "200/200 [==============================] - 54s 270ms/step - loss: 0.0234 - accuracy: 0.9946\n",
            "Epoch 13/15\n",
            "200/200 [==============================] - 54s 270ms/step - loss: 0.0209 - accuracy: 0.9952\n",
            "Epoch 14/15\n",
            "200/200 [==============================] - 54s 270ms/step - loss: 0.0189 - accuracy: 0.9950\n",
            "Epoch 15/15\n",
            "200/200 [==============================] - 55s 272ms/step - loss: 0.0172 - accuracy: 0.9959\n",
            "Accuracy:  56.49999976158142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yahoo Test Data"
      ],
      "metadata": {
        "id": "uROExx10OFCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Yahoo_Test_Data\n",
        "\n",
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(40000,embedding_vector_length,input_length = 501))\n",
        "model.add(LSTM(32,dropout=0.2, return_sequences = True ))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(2,activation = 'softmax'))\n",
        "model.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train,y_train, epochs = 15 , batch_size=23)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p39Ya_m8F3cK",
        "outputId": "fc337341-b0b6-46fb-af39-ba106b9c892e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 501, 32)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 501, 32)           8320      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                8320      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,706\n",
            "Trainable params: 1,296,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "200/200 [==============================] - 64s 302ms/step - loss: 0.6168 - accuracy: 0.6804\n",
            "Epoch 2/15\n",
            "200/200 [==============================] - 55s 275ms/step - loss: 0.4445 - accuracy: 0.7954\n",
            "Epoch 3/15\n",
            "200/200 [==============================] - 55s 274ms/step - loss: 0.1996 - accuracy: 0.9248\n",
            "Epoch 4/15\n",
            "200/200 [==============================] - 55s 276ms/step - loss: 0.0970 - accuracy: 0.9676\n",
            "Epoch 5/15\n",
            "200/200 [==============================] - 56s 278ms/step - loss: 0.0518 - accuracy: 0.9874\n",
            "Epoch 6/15\n",
            "200/200 [==============================] - 55s 277ms/step - loss: 0.0439 - accuracy: 0.9889\n",
            "Epoch 7/15\n",
            "200/200 [==============================] - 55s 277ms/step - loss: 0.0287 - accuracy: 0.9946\n",
            "Epoch 8/15\n",
            "200/200 [==============================] - 55s 276ms/step - loss: 0.0459 - accuracy: 0.9865\n",
            "Epoch 9/15\n",
            "200/200 [==============================] - 55s 276ms/step - loss: 0.0310 - accuracy: 0.9920\n",
            "Epoch 10/15\n",
            "200/200 [==============================] - 55s 273ms/step - loss: 0.0180 - accuracy: 0.9963\n",
            "Epoch 11/15\n",
            "200/200 [==============================] - 55s 273ms/step - loss: 0.0198 - accuracy: 0.9954\n",
            "Epoch 12/15\n",
            "200/200 [==============================] - 54s 271ms/step - loss: 0.0196 - accuracy: 0.9941\n",
            "Epoch 13/15\n",
            "200/200 [==============================] - 56s 278ms/step - loss: 0.0201 - accuracy: 0.9948\n",
            "Epoch 14/15\n",
            "200/200 [==============================] - 54s 268ms/step - loss: 0.0128 - accuracy: 0.9957\n",
            "Epoch 15/15\n",
            "200/200 [==============================] - 54s 269ms/step - loss: 0.0122 - accuracy: 0.9972\n",
            "Accuracy:  54.500001668930054\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Textual-Coherence.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}