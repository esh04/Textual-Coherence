{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9ZKbXs3MpFzQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import argparse\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchtext\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_4iAL3nrcE4",
        "outputId": "59dcbeac-2c6f-4bce-a919-38f583ede96e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipnTRok-pAKK",
        "outputId": "7a96121c-3b1f-44cd-c366-3a8153ea150c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "sw = stopwords.words('english') \n",
        "\n",
        "\n",
        "class Tokenizer:\n",
        "\n",
        "    def __init__(self, file, threshold=5):\n",
        "        self.file = file\n",
        "        self.data = pd.read_csv(file)\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def preprocess(self):\n",
        "        tokenizer = torchtext.data.utils.get_tokenizer('spacy', language='en')\n",
        "        tokens = []\n",
        "        sentence_list=[]\n",
        "        for text in self.data['text'].tolist():\n",
        "            tokens.append(tokenizer(text))\n",
        "            sentence_list.append(text.split('.'))\n",
        "\n",
        "        self.data['sentences_list'] = sentence_list\n",
        "        counter = Counter()\n",
        "        for line in tokens:\n",
        "            for word in line:\n",
        "                counter[word] += 1\n",
        "        # print(len(counter.items()), len(counter.most_common()))\n",
        "\n",
        "        # remove all words that have frequency less than threshold\n",
        "        # counter_threshold = {k:v for k,v in counter.items() if v >= self.threshold}\n",
        "\n",
        "        # create mappings\n",
        "        # mapper = {word:idx+1 for idx,word in enumerate(counter_threshold.keys())}\n",
        "        # inverse_mapper = {idx+1:word for idx,word in enumerate(counter_threshold.keys())}\n",
        "\n",
        "        # sos_idx = len(counter_threshold.keys())\n",
        "        # eos_idx = len(counter_threshold.keys()) + 1\n",
        "        # other_idx = len(counter_threshold.keys()) + 2\n",
        "\n",
        "        # mapped_tokens = []\n",
        "\n",
        "        # for line in tokens:\n",
        "        #     mapped_line = [sos_idx]\n",
        "        #     for word in line:\n",
        "        #       # map words to their mappings and to other otherwise\n",
        "        #         mapped_line.append(mapper.get(word, other_idx))\n",
        "        #     mapped_line.append(eos_idx)\n",
        "        #     mapped_tokens.append(mapped_line)\n",
        "\n",
        "        # inverse_mapper[other_idx] = \"__OTHER__\"\n",
        "        # inverse_mapper[sos_idx] = \"__SOS__\"\n",
        "        # inverse_mapper[eos_idx] = \"__EOS__\"\n",
        "        # inverse_mapper[0] = \"__PADDING__\"\n",
        "\n",
        "        mapper = {word[0]: idx+1 for idx,\n",
        "                  word in enumerate(counter.most_common())}\n",
        "        inverse_mapper = {idx+1: word[0] for idx,\n",
        "                          word in enumerate(counter.most_common())}\n",
        "\n",
        "        # sos_idx = len(counter_threshold.keys())\n",
        "        # eos_idx = len(counter_threshold.keys()) + 1\n",
        "        other_idx = len(counter.keys())\n",
        "\n",
        "        mapped_tokens = []\n",
        "\n",
        "        for line in tokens:\n",
        "            mapped_line = []\n",
        "            for word in line:\n",
        "              # map words to their mappings and to other otherwise\n",
        "                mapped_line.append(mapper.get(word, other_idx))\n",
        "            mapped_tokens.append(mapped_line)\n",
        "\n",
        "        # inverse_mapper[other_idx] = \"__OTHER__\"\n",
        "        # inverse_mapper[sos_idx] = \"__SOS__\"\n",
        "        # inverse_mapper[eos_idx] = \"__EOS__\"\n",
        "        # inverse_mapper[0] = \"__PADDING__\"\n",
        "\n",
        "        return mapped_tokens, inverse_mapper\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def similarity_paragraph(data):\n",
        "    # data = self.data\n",
        "    sim_list = []\n",
        "    for para in data['sentences_list'].tolist():\n",
        "      sim = 2000\n",
        "      start = para[0]\n",
        "      para = para[1:]\n",
        "      for sent in para:            \n",
        "        # tokenization\n",
        "        X_list = word_tokenize(start) \n",
        "        Y_list = word_tokenize(sent)\n",
        "          \n",
        "        # sw contains the list of stopwords\n",
        "        l1 =[];l2 =[]\n",
        "          \n",
        "        # remove stop words from the string\n",
        "        X_set = {w for w in X_list if not w in sw} \n",
        "        Y_set = {w for w in Y_list if not w in sw}\n",
        "          \n",
        "        # form a set containing keywords of both strings \n",
        "        rvector = X_set.union(Y_set) \n",
        "        for w in rvector:\n",
        "            if w in X_set: l1.append(1) # create a vector\n",
        "            else: l1.append(0)\n",
        "            if w in Y_set: l2.append(1)\n",
        "            else: l2.append(0)\n",
        "        c = 0\n",
        "          \n",
        "        # cosine formula \n",
        "        for i in range(len(rvector)):\n",
        "            c+= l1[i]*l2[i]\n",
        "        try:\n",
        "          cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
        "          if sim > cosine:\n",
        "            sim=cosine\n",
        "          # sim += cosine\n",
        "        except:\n",
        "          sim += 0\n",
        "          \n",
        "        start = sent\n",
        "      \n",
        "      # sim = sim/(len(para)+1)\n",
        "      sim_list.append(sim)\n",
        "    \n",
        "    data['similarity'] = sim_list\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "          \n",
        "          # print(\"similarity: \", cosine)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6LRLl-EAOeCL"
      },
      "outputs": [],
      "source": [
        "# training data\n",
        "data1 = pd.read_csv('/content/gdrive/MyDrive/NLP-Project/Clinton_train.csv')\n",
        "data2 = pd.read_csv('/content/gdrive/MyDrive/NLP-Project/Yahoo_train.csv')\n",
        "data3 = pd.read_csv('/content/gdrive/MyDrive/NLP-Project/Yelp_train.csv')\n",
        "data4 = pd.read_csv('/content/gdrive/MyDrive/NLP-Project/Enron_train.csv')\n",
        "\n",
        "data5 = pd.read_csv('/content/gdrive/MyDrive/NLP-Project/Yahoo_test.csv')\n",
        "data6 = pd.read_csv('/content/gdrive/MyDrive/NLP-Project/Yelp_test.csv')\n",
        "data7 = pd.read_csv('/content/gdrive/MyDrive/NLP-Project/Enron_test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p0m7bl6PO1oL"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([data1, data2, data3, data4, data5, data6, data7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ixt94NWwP8Hi"
      },
      "outputs": [],
      "source": [
        "data.to_csv('/content/gdrive/MyDrive/NLP-Project/new_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AGJivFqTNcF6"
      },
      "outputs": [],
      "source": [
        "# train = Tokenizer(\"/content/gdrive/MyDrive/GCDC_rerelease/train.csv\")\n",
        "# test = Tokenizer(\"/content/gdrive/MyDrive/GCDC_rerelease/Yahoo_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6HowKzJMQLOM"
      },
      "outputs": [],
      "source": [
        "train = Tokenizer(\"/content/gdrive/MyDrive/NLP-Project/new_train.csv\")\n",
        "test = Tokenizer(\"/content/gdrive/MyDrive/NLP-Project/Clinton_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKh63JzxQteb",
        "outputId": "1ca6277f-82ac-487a-fb00-c6d15366be5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4600"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(train.data)\n",
        "# len(test.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yS39RPLu83j",
        "outputId": "12337718-bc89-4b8a-ceb6-c8e8ad27c8fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# lst=[]\n",
        "# for i in range(1000):\n",
        "#   if train.data['labelA'][i]==3:\n",
        "#     lst.append([0,0,1])\n",
        "#   elif train.data['labelA'][i]==2:\n",
        "#     lst.append([0,1,0])\n",
        "#   elif train.data['labelA'][i]==1:\n",
        "#     lst.append([1,0,0])\n",
        "\n",
        "# train.data['h_e']=lst\n",
        "\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "lst = array(train.data['labelA'])\n",
        "encoded = to_categorical(lst)\n",
        "print(encoded)\n",
        "# inverted = argmax(encoded[0])\n",
        "# print(inverted)\n",
        "\n",
        "# train.data['h_e'] = encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rK2UhBczvhRW"
      },
      "outputs": [],
      "source": [
        "# lst=[]\n",
        "# for i in range(200):\n",
        "#   if test.data['labelA'][i]==3:\n",
        "#     lst.append([0,0,1])\n",
        "#   elif test.data['labelA'][i]==2:\n",
        "#     lst.append([0,1,0])\n",
        "#   elif test.data['labelA'][i]==1:\n",
        "#     lst.append([1,0,0])\n",
        "\n",
        "# test.data['h_e']=lst\n",
        "\n",
        "lst = array(test.data['labelA'])\n",
        "t_encoded = to_categorical(lst)\n",
        "# test.data['h_e'] = encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ONuCV7pSqCTb"
      },
      "outputs": [],
      "source": [
        "train_mapping, inv_train_mapping = train.preprocess()\n",
        "test_mapping, inv_test_mapping = test.preprocess()\n",
        "\n",
        "# train.data = similarity_paragraph(train.data)\n",
        "# test.data = similarity_paragraph(test.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "QqDO2UAwnFvA",
        "outputId": "bfccbc3d-4616-4da8-96a1-cb84c324efc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0      text_id  \\\n",
              "0              0  C05796441_2   \n",
              "1              1  C05786430_1   \n",
              "2              2  C05780653_3   \n",
              "3              3  C05782181_1   \n",
              "4              4  C05785147_0   \n",
              "...          ...          ...   \n",
              "4595         195      1353855   \n",
              "4596         196      1131834   \n",
              "4597         197       725369   \n",
              "4598         198       766379   \n",
              "4599         199      1122541   \n",
              "\n",
              "                                                subject  \\\n",
              "0                                                   NaN   \n",
              "1                                   Department of State   \n",
              "2                                                   NaN   \n",
              "3     Libyan CG Pol Dirs mtg @ Istanbul @ 14:00 Thur...   \n",
              "4                                                Mexico   \n",
              "...                                                 ...   \n",
              "4595                                  Comments of Wolak   \n",
              "4596                                                NBC   \n",
              "4597                                        Gallup Peak   \n",
              "4598                             New TW Contract System   \n",
              "4599                                          UGGGHHHHH   \n",
              "\n",
              "                                                   text  ratingA1  ratingA2  \\\n",
              "0     Cheryl:\\n\\nAre we in a good place to begin pap...         3         2   \n",
              "1     Our friend, General Joe Ballard owns The Raven...         2         1   \n",
              "2     Outstanding news! Miki Rakic called about 10 m...         2         3   \n",
              "3     Responding to separate emails from Uzra + Jeff...         1         2   \n",
              "4     Guy from Mexico is in NY and is cooperating. D...         2         1   \n",
              "...                                                 ...       ...       ...   \n",
              "4595  Wolak makes some good points.  In ERCOT, Enron...         2         3   \n",
              "4596  The reason NBC will not take cash is the prefe...         2         2   \n",
              "4597  All GC's\\n\\nAfter utilizing the Gallup Peak Av...         3         3   \n",
              "4598  Lindy,\\n\\nJust wanted to let you know that we ...         3         2   \n",
              "4599  I know, I know.  It's still weird to me.  Whil...         2         1   \n",
              "\n",
              "      ratingA3  labelA  ratingM1  ratingM2  ratingM3  ratingM4  ratingM5  \\\n",
              "0            1       2         2         2         3         1         2   \n",
              "1            3       2         3         2         3         1         3   \n",
              "2            3       3         2         2         3         2         3   \n",
              "3            1       1         2         2         1         3         1   \n",
              "4            1       1         1         1         2         3         1   \n",
              "...        ...     ...       ...       ...       ...       ...       ...   \n",
              "4595         2       3         2         2         2         2         2   \n",
              "4596         1       1         2         2         2         2         2   \n",
              "4597         3       3         3         2         2         3         2   \n",
              "4598         1       2         2         3         2         2         2   \n",
              "4599         2       1         1         2         1         1         2   \n",
              "\n",
              "      labelM question_title question  \\\n",
              "0          2            NaN      NaN   \n",
              "1          3            NaN      NaN   \n",
              "2          3            NaN      NaN   \n",
              "3          1            NaN      NaN   \n",
              "4          1            NaN      NaN   \n",
              "...      ...            ...      ...   \n",
              "4595       2            NaN      NaN   \n",
              "4596       2            NaN      NaN   \n",
              "4597       3            NaN      NaN   \n",
              "4598       2            NaN      NaN   \n",
              "4599       1            NaN      NaN   \n",
              "\n",
              "                                         sentences_list  \\\n",
              "0     [Cheryl:\\n\\nAre we in a good place to begin pa...   \n",
              "1     [Our friend, General Joe Ballard owns The Rave...   \n",
              "2     [Outstanding news! Miki Rakic called about 10 ...   \n",
              "3     [Responding to separate emails from Uzra + Jef...   \n",
              "4     [Guy from Mexico is in NY and is cooperating, ...   \n",
              "...                                                 ...   \n",
              "4595  [Wolak makes some good points,   In ERCOT, Enr...   \n",
              "4596  [The reason NBC will not take cash is the pref...   \n",
              "4597  [All GC's\\n\\nAfter utilizing the Gallup Peak A...   \n",
              "4598  [Lindy,\\n\\nJust wanted to let you know that we...   \n",
              "4599  [I know, I know,   It's still weird to me,   W...   \n",
              "\n",
              "                                               encoding  \n",
              "0     [527, 104, 15, 1437, 22, 10, 7, 75, 97, 4, 869...  \n",
              "1     [398, 369, 3, 1247, 2174, 9564, 3567, 29, 9565...  \n",
              "2     [14037, 626, 37, 14038, 19227, 253, 54, 371, 3...  \n",
              "3     [19240, 4, 1518, 3176, 43, 14041, 1133, 581, 1...  \n",
              "4     [6124, 43, 1011, 12, 10, 1566, 5, 12, 6699, 1,...  \n",
              "...                                                 ...  \n",
              "4595  [36597, 433, 72, 75, 555, 1, 9, 166, 2846, 3, ...  \n",
              "4596  [29, 404, 4401, 28, 26, 134, 642, 12, 2, 4060,...  \n",
              "4597  [359, 13652, 25, 15, 444, 18327, 2, 9773, 9547...  \n",
              "4598  [8271, 3, 15, 389, 202, 4, 179, 13, 68, 11, 22...  \n",
              "4599  [6, 68, 3, 6, 68, 1, 9, 73, 25, 144, 1866, 4, ...  \n",
              "\n",
              "[4600 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09c06025-b850-491a-ac72-0decdf0d9e1d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text_id</th>\n",
              "      <th>subject</th>\n",
              "      <th>text</th>\n",
              "      <th>ratingA1</th>\n",
              "      <th>ratingA2</th>\n",
              "      <th>ratingA3</th>\n",
              "      <th>labelA</th>\n",
              "      <th>ratingM1</th>\n",
              "      <th>ratingM2</th>\n",
              "      <th>ratingM3</th>\n",
              "      <th>ratingM4</th>\n",
              "      <th>ratingM5</th>\n",
              "      <th>labelM</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question</th>\n",
              "      <th>sentences_list</th>\n",
              "      <th>encoding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>C05796441_2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cheryl:\\n\\nAre we in a good place to begin pap...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Cheryl:\\n\\nAre we in a good place to begin pa...</td>\n",
              "      <td>[527, 104, 15, 1437, 22, 10, 7, 75, 97, 4, 869...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>C05786430_1</td>\n",
              "      <td>Department of State</td>\n",
              "      <td>Our friend, General Joe Ballard owns The Raven...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Our friend, General Joe Ballard owns The Rave...</td>\n",
              "      <td>[398, 369, 3, 1247, 2174, 9564, 3567, 29, 9565...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>C05780653_3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Outstanding news! Miki Rakic called about 10 m...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Outstanding news! Miki Rakic called about 10 ...</td>\n",
              "      <td>[14037, 626, 37, 14038, 19227, 253, 54, 371, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>C05782181_1</td>\n",
              "      <td>Libyan CG Pol Dirs mtg @ Istanbul @ 14:00 Thur...</td>\n",
              "      <td>Responding to separate emails from Uzra + Jeff...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Responding to separate emails from Uzra + Jef...</td>\n",
              "      <td>[19240, 4, 1518, 3176, 43, 14041, 1133, 581, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>C05785147_0</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>Guy from Mexico is in NY and is cooperating. D...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Guy from Mexico is in NY and is cooperating, ...</td>\n",
              "      <td>[6124, 43, 1011, 12, 10, 1566, 5, 12, 6699, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4595</th>\n",
              "      <td>195</td>\n",
              "      <td>1353855</td>\n",
              "      <td>Comments of Wolak</td>\n",
              "      <td>Wolak makes some good points.  In ERCOT, Enron...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Wolak makes some good points,   In ERCOT, Enr...</td>\n",
              "      <td>[36597, 433, 72, 75, 555, 1, 9, 166, 2846, 3, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>196</td>\n",
              "      <td>1131834</td>\n",
              "      <td>NBC</td>\n",
              "      <td>The reason NBC will not take cash is the prefe...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[The reason NBC will not take cash is the pref...</td>\n",
              "      <td>[29, 404, 4401, 28, 26, 134, 642, 12, 2, 4060,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>197</td>\n",
              "      <td>725369</td>\n",
              "      <td>Gallup Peak</td>\n",
              "      <td>All GC's\\n\\nAfter utilizing the Gallup Peak Av...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[All GC's\\n\\nAfter utilizing the Gallup Peak A...</td>\n",
              "      <td>[359, 13652, 25, 15, 444, 18327, 2, 9773, 9547...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>198</td>\n",
              "      <td>766379</td>\n",
              "      <td>New TW Contract System</td>\n",
              "      <td>Lindy,\\n\\nJust wanted to let you know that we ...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Lindy,\\n\\nJust wanted to let you know that we...</td>\n",
              "      <td>[8271, 3, 15, 389, 202, 4, 179, 13, 68, 11, 22...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>199</td>\n",
              "      <td>1122541</td>\n",
              "      <td>UGGGHHHHH</td>\n",
              "      <td>I know, I know.  It's still weird to me.  Whil...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[I know, I know,   It's still weird to me,   W...</td>\n",
              "      <td>[6, 68, 3, 6, 68, 1, 9, 73, 25, 144, 1866, 4, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4600 rows Ã— 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09c06025-b850-491a-ac72-0decdf0d9e1d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09c06025-b850-491a-ac72-0decdf0d9e1d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09c06025-b850-491a-ac72-0decdf0d9e1d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# new_data = open('/content/drive/MyDrive/GCDC_rerelease/mapped_tokens_Yelp_train.csv.pkl','rb')\n",
        "# new_t_data = open('/content/drive/MyDrive/GCDC_rerelease/mapped_tokens_Yelp_test.csv.pkl','rb')\n",
        "# train_mapping = pickle.load(new_data)\n",
        "# test_mapping = pickle.load(new_t_data)\n",
        "\n",
        "len(train_mapping)\n",
        "# train_mapping\n",
        "train.data['encoding'] = train_mapping\n",
        "test.data['encoding'] = test_mapping\n",
        "train.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Lo-MrHNzvsJw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "90a0b22a-851d-4db3-e2ac-594370c5f68e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0      text_id  \\\n",
              "0              0  C05796441_2   \n",
              "1              1  C05786430_1   \n",
              "2              2  C05780653_3   \n",
              "3              3  C05782181_1   \n",
              "4              4  C05785147_0   \n",
              "...          ...          ...   \n",
              "4595         195      1353855   \n",
              "4596         196      1131834   \n",
              "4597         197       725369   \n",
              "4598         198       766379   \n",
              "4599         199      1122541   \n",
              "\n",
              "                                                subject  \\\n",
              "0                                                   NaN   \n",
              "1                                   Department of State   \n",
              "2                                                   NaN   \n",
              "3     Libyan CG Pol Dirs mtg @ Istanbul @ 14:00 Thur...   \n",
              "4                                                Mexico   \n",
              "...                                                 ...   \n",
              "4595                                  Comments of Wolak   \n",
              "4596                                                NBC   \n",
              "4597                                        Gallup Peak   \n",
              "4598                             New TW Contract System   \n",
              "4599                                          UGGGHHHHH   \n",
              "\n",
              "                                                   text  ratingA1  ratingA2  \\\n",
              "0     Cheryl:\\n\\nAre we in a good place to begin pap...         3         2   \n",
              "1     Our friend, General Joe Ballard owns The Raven...         2         1   \n",
              "2     Outstanding news! Miki Rakic called about 10 m...         2         3   \n",
              "3     Responding to separate emails from Uzra + Jeff...         1         2   \n",
              "4     Guy from Mexico is in NY and is cooperating. D...         2         1   \n",
              "...                                                 ...       ...       ...   \n",
              "4595  Wolak makes some good points.  In ERCOT, Enron...         2         3   \n",
              "4596  The reason NBC will not take cash is the prefe...         2         2   \n",
              "4597  All GC's\\n\\nAfter utilizing the Gallup Peak Av...         3         3   \n",
              "4598  Lindy,\\n\\nJust wanted to let you know that we ...         3         2   \n",
              "4599  I know, I know.  It's still weird to me.  Whil...         2         1   \n",
              "\n",
              "      ratingA3  labelA  ratingM1  ratingM2  ratingM3  ratingM4  ratingM5  \\\n",
              "0            1       2         2         2         3         1         2   \n",
              "1            3       2         3         2         3         1         3   \n",
              "2            3       3         2         2         3         2         3   \n",
              "3            1       1         2         2         1         3         1   \n",
              "4            1       1         1         1         2         3         1   \n",
              "...        ...     ...       ...       ...       ...       ...       ...   \n",
              "4595         2       3         2         2         2         2         2   \n",
              "4596         1       1         2         2         2         2         2   \n",
              "4597         3       3         3         2         2         3         2   \n",
              "4598         1       2         2         3         2         2         2   \n",
              "4599         2       1         1         2         1         1         2   \n",
              "\n",
              "      labelM question_title question  \\\n",
              "0          2            NaN      NaN   \n",
              "1          3            NaN      NaN   \n",
              "2          3            NaN      NaN   \n",
              "3          1            NaN      NaN   \n",
              "4          1            NaN      NaN   \n",
              "...      ...            ...      ...   \n",
              "4595       2            NaN      NaN   \n",
              "4596       2            NaN      NaN   \n",
              "4597       3            NaN      NaN   \n",
              "4598       2            NaN      NaN   \n",
              "4599       1            NaN      NaN   \n",
              "\n",
              "                                         sentences_list  \\\n",
              "0     [Cheryl:\\n\\nAre we in a good place to begin pa...   \n",
              "1     [Our friend, General Joe Ballard owns The Rave...   \n",
              "2     [Outstanding news! Miki Rakic called about 10 ...   \n",
              "3     [Responding to separate emails from Uzra + Jef...   \n",
              "4     [Guy from Mexico is in NY and is cooperating, ...   \n",
              "...                                                 ...   \n",
              "4595  [Wolak makes some good points,   In ERCOT, Enr...   \n",
              "4596  [The reason NBC will not take cash is the pref...   \n",
              "4597  [All GC's\\n\\nAfter utilizing the Gallup Peak A...   \n",
              "4598  [Lindy,\\n\\nJust wanted to let you know that we...   \n",
              "4599  [I know, I know,   It's still weird to me,   W...   \n",
              "\n",
              "                                               encoding  \n",
              "0     [527, 104, 15, 1437, 22, 10, 7, 75, 97, 4, 869...  \n",
              "1     [398, 369, 3, 1247, 2174, 9564, 3567, 29, 9565...  \n",
              "2     [14037, 626, 37, 14038, 19227, 253, 54, 371, 3...  \n",
              "3     [19240, 4, 1518, 3176, 43, 14041, 1133, 581, 1...  \n",
              "4     [6124, 43, 1011, 12, 10, 1566, 5, 12, 6699, 1,...  \n",
              "...                                                 ...  \n",
              "4595  [36597, 433, 72, 75, 555, 1, 9, 166, 2846, 3, ...  \n",
              "4596  [29, 404, 4401, 28, 26, 134, 642, 12, 2, 4060,...  \n",
              "4597  [359, 13652, 25, 15, 444, 18327, 2, 9773, 9547...  \n",
              "4598  [8271, 3, 15, 389, 202, 4, 179, 13, 68, 11, 22...  \n",
              "4599  [6, 68, 3, 6, 68, 1, 9, 73, 25, 144, 1866, 4, ...  \n",
              "\n",
              "[4600 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-145cf6a9-7a1b-46bd-b4a3-1f8c4d1e1b27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text_id</th>\n",
              "      <th>subject</th>\n",
              "      <th>text</th>\n",
              "      <th>ratingA1</th>\n",
              "      <th>ratingA2</th>\n",
              "      <th>ratingA3</th>\n",
              "      <th>labelA</th>\n",
              "      <th>ratingM1</th>\n",
              "      <th>ratingM2</th>\n",
              "      <th>ratingM3</th>\n",
              "      <th>ratingM4</th>\n",
              "      <th>ratingM5</th>\n",
              "      <th>labelM</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question</th>\n",
              "      <th>sentences_list</th>\n",
              "      <th>encoding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>C05796441_2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cheryl:\\n\\nAre we in a good place to begin pap...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Cheryl:\\n\\nAre we in a good place to begin pa...</td>\n",
              "      <td>[527, 104, 15, 1437, 22, 10, 7, 75, 97, 4, 869...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>C05786430_1</td>\n",
              "      <td>Department of State</td>\n",
              "      <td>Our friend, General Joe Ballard owns The Raven...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Our friend, General Joe Ballard owns The Rave...</td>\n",
              "      <td>[398, 369, 3, 1247, 2174, 9564, 3567, 29, 9565...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>C05780653_3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Outstanding news! Miki Rakic called about 10 m...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Outstanding news! Miki Rakic called about 10 ...</td>\n",
              "      <td>[14037, 626, 37, 14038, 19227, 253, 54, 371, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>C05782181_1</td>\n",
              "      <td>Libyan CG Pol Dirs mtg @ Istanbul @ 14:00 Thur...</td>\n",
              "      <td>Responding to separate emails from Uzra + Jeff...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Responding to separate emails from Uzra + Jef...</td>\n",
              "      <td>[19240, 4, 1518, 3176, 43, 14041, 1133, 581, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>C05785147_0</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>Guy from Mexico is in NY and is cooperating. D...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Guy from Mexico is in NY and is cooperating, ...</td>\n",
              "      <td>[6124, 43, 1011, 12, 10, 1566, 5, 12, 6699, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4595</th>\n",
              "      <td>195</td>\n",
              "      <td>1353855</td>\n",
              "      <td>Comments of Wolak</td>\n",
              "      <td>Wolak makes some good points.  In ERCOT, Enron...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Wolak makes some good points,   In ERCOT, Enr...</td>\n",
              "      <td>[36597, 433, 72, 75, 555, 1, 9, 166, 2846, 3, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4596</th>\n",
              "      <td>196</td>\n",
              "      <td>1131834</td>\n",
              "      <td>NBC</td>\n",
              "      <td>The reason NBC will not take cash is the prefe...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[The reason NBC will not take cash is the pref...</td>\n",
              "      <td>[29, 404, 4401, 28, 26, 134, 642, 12, 2, 4060,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4597</th>\n",
              "      <td>197</td>\n",
              "      <td>725369</td>\n",
              "      <td>Gallup Peak</td>\n",
              "      <td>All GC's\\n\\nAfter utilizing the Gallup Peak Av...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[All GC's\\n\\nAfter utilizing the Gallup Peak A...</td>\n",
              "      <td>[359, 13652, 25, 15, 444, 18327, 2, 9773, 9547...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4598</th>\n",
              "      <td>198</td>\n",
              "      <td>766379</td>\n",
              "      <td>New TW Contract System</td>\n",
              "      <td>Lindy,\\n\\nJust wanted to let you know that we ...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Lindy,\\n\\nJust wanted to let you know that we...</td>\n",
              "      <td>[8271, 3, 15, 389, 202, 4, 179, 13, 68, 11, 22...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4599</th>\n",
              "      <td>199</td>\n",
              "      <td>1122541</td>\n",
              "      <td>UGGGHHHHH</td>\n",
              "      <td>I know, I know.  It's still weird to me.  Whil...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[I know, I know,   It's still weird to me,   W...</td>\n",
              "      <td>[6, 68, 3, 6, 68, 1, 9, 73, 25, 144, 1866, 4, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4600 rows Ã— 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-145cf6a9-7a1b-46bd-b4a3-1f8c4d1e1b27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-145cf6a9-7a1b-46bd-b4a3-1f8c4d1e1b27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-145cf6a9-7a1b-46bd-b4a3-1f8c4d1e1b27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tFqqpNYJvtIc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "fc14eacb-a03f-45ab-f8d6-11d30f10becc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         text_id                                            subject  \\\n",
              "0    C05760125_1                        Hilda Solis Tom and Craig--   \n",
              "1    C05768263_2                                                NaN   \n",
              "2    C05771873_1                    Framing Statement - State Draft   \n",
              "3    C05768528_2                                                NaN   \n",
              "4    C05775052_1  The matter I raised on my end of the converati...   \n",
              "..           ...                                                ...   \n",
              "195  C05782457_0           arming the rebels, women, and small arms   \n",
              "196  C05739879_1                                                NaN   \n",
              "197  C05765100_1                                                NaN   \n",
              "198  C05773055_1                                                NaN   \n",
              "199  C05784364_6                                                NaN   \n",
              "\n",
              "                                                  text  ratingA1  ratingA2  \\\n",
              "0    Madame Secretary:\\n\\nThank you for reaching ou...         3         3   \n",
              "1    Cheryl, Jake,\\n\\nI received a call from Masood...         3         3   \n",
              "2    We anticipate the release of what are claimed ...         3         3   \n",
              "3    Spoke to Ed Levine today to follow up on Frida...         3         3   \n",
              "4    Purely to update: Tom had me in for lunch at t...         2         1   \n",
              "..                                                 ...       ...       ...   \n",
              "195  Kavita Ramdas, until recently the head of the ...         3         3   \n",
              "196  I called PM el-Keib this morning to get his ta...         2         3   \n",
              "197  Department of State Ranks High as Employer for...         2         3   \n",
              "198  Dear Hillary Wanted to take a minute to thank ...         2         3   \n",
              "199  Ambassador Siddique:\\n\\nGreat speaking with yo...         2         2   \n",
              "\n",
              "     ratingA3  labelA  ratingM1  ratingM2  ratingM3  ratingM4  ratingM5  \\\n",
              "0           3       3         2         3         2         2         2   \n",
              "1           3       3         2         2         2         3         2   \n",
              "2           3       3         3         2         3         2         1   \n",
              "3           3       3         3         2         2         1         3   \n",
              "4           3       2         2         2         3         1         2   \n",
              "..        ...     ...       ...       ...       ...       ...       ...   \n",
              "195         2       3         1         1         2         2         2   \n",
              "196         2       3         1         1         2         2         1   \n",
              "197         2       3         2         3         3         2         3   \n",
              "198         2       3         2         2         2         2         3   \n",
              "199         3       3         2         2         3         1         3   \n",
              "\n",
              "     labelM                                     sentences_list  \\\n",
              "0         2  [Madame Secretary:\\n\\nThank you for reaching o...   \n",
              "1         2  [Cheryl, Jake,\\n\\nI received a call from Masoo...   \n",
              "2         2  [We anticipate the release of what are claimed...   \n",
              "3         2  [Spoke to Ed Levine today to follow up on Frid...   \n",
              "4         2  [Purely to update: Tom had me in for lunch at ...   \n",
              "..      ...                                                ...   \n",
              "195       1  [Kavita Ramdas, until recently the head of the...   \n",
              "196       1  [I called PM el-Keib this morning to get his t...   \n",
              "197       3  [Department of State Ranks High as Employer fo...   \n",
              "198       2  [Dear Hillary Wanted to take a minute to thank...   \n",
              "199       2  [Ambassador Siddique:\\n\\nGreat speaking with y...   \n",
              "\n",
              "                                              encoding  \n",
              "0    [1045, 44, 36, 7, 320, 16, 14, 2849, 77, 4, 44...  \n",
              "1    [199, 3, 183, 3, 7, 11, 559, 9, 123, 33, 2878,...  \n",
              "2    [43, 2884, 1, 1060, 6, 78, 26, 1365, 4, 19, 40...  \n",
              "3    [2905, 4, 495, 2906, 82, 4, 445, 63, 13, 490, ...  \n",
              "4    [2924, 4, 498, 36, 396, 49, 48, 8, 14, 726, 29...  \n",
              "..                                                 ...  \n",
              "195  [6298, 6299, 3, 463, 790, 1, 613, 6, 1, 741, 1...  \n",
              "196  [11, 207, 318, 6323, 20, 6324, 17, 223, 4, 55,...  \n",
              "197  [127, 6, 71, 6345, 6346, 25, 6347, 14, 557, 63...  \n",
              "198  [187, 285, 6367, 4, 115, 9, 2824, 4, 324, 16, ...  \n",
              "199  [168, 6377, 36, 7, 2692, 1228, 15, 16, 82, 2, ...  \n",
              "\n",
              "[200 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6915a7f3-5948-4f8b-918f-d24364cb2d7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>subject</th>\n",
              "      <th>text</th>\n",
              "      <th>ratingA1</th>\n",
              "      <th>ratingA2</th>\n",
              "      <th>ratingA3</th>\n",
              "      <th>labelA</th>\n",
              "      <th>ratingM1</th>\n",
              "      <th>ratingM2</th>\n",
              "      <th>ratingM3</th>\n",
              "      <th>ratingM4</th>\n",
              "      <th>ratingM5</th>\n",
              "      <th>labelM</th>\n",
              "      <th>sentences_list</th>\n",
              "      <th>encoding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C05760125_1</td>\n",
              "      <td>Hilda Solis Tom and Craig--</td>\n",
              "      <td>Madame Secretary:\\n\\nThank you for reaching ou...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[Madame Secretary:\\n\\nThank you for reaching o...</td>\n",
              "      <td>[1045, 44, 36, 7, 320, 16, 14, 2849, 77, 4, 44...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C05768263_2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cheryl, Jake,\\n\\nI received a call from Masood...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[Cheryl, Jake,\\n\\nI received a call from Masoo...</td>\n",
              "      <td>[199, 3, 183, 3, 7, 11, 559, 9, 123, 33, 2878,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C05771873_1</td>\n",
              "      <td>Framing Statement - State Draft</td>\n",
              "      <td>We anticipate the release of what are claimed ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[We anticipate the release of what are claimed...</td>\n",
              "      <td>[43, 2884, 1, 1060, 6, 78, 26, 1365, 4, 19, 40...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C05768528_2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Spoke to Ed Levine today to follow up on Frida...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>[Spoke to Ed Levine today to follow up on Frid...</td>\n",
              "      <td>[2905, 4, 495, 2906, 82, 4, 445, 63, 13, 490, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C05775052_1</td>\n",
              "      <td>The matter I raised on my end of the converati...</td>\n",
              "      <td>Purely to update: Tom had me in for lunch at t...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[Purely to update: Tom had me in for lunch at ...</td>\n",
              "      <td>[2924, 4, 498, 36, 396, 49, 48, 8, 14, 726, 29...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>C05782457_0</td>\n",
              "      <td>arming the rebels, women, and small arms</td>\n",
              "      <td>Kavita Ramdas, until recently the head of the ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[Kavita Ramdas, until recently the head of the...</td>\n",
              "      <td>[6298, 6299, 3, 463, 790, 1, 613, 6, 1, 741, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>C05739879_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I called PM el-Keib this morning to get his ta...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[I called PM el-Keib this morning to get his t...</td>\n",
              "      <td>[11, 207, 318, 6323, 20, 6324, 17, 223, 4, 55,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>C05765100_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Department of State Ranks High as Employer for...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[Department of State Ranks High as Employer fo...</td>\n",
              "      <td>[127, 6, 71, 6345, 6346, 25, 6347, 14, 557, 63...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>C05773055_1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dear Hillary Wanted to take a minute to thank ...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>[Dear Hillary Wanted to take a minute to thank...</td>\n",
              "      <td>[187, 285, 6367, 4, 115, 9, 2824, 4, 324, 16, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>C05784364_6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ambassador Siddique:\\n\\nGreat speaking with yo...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>[Ambassador Siddique:\\n\\nGreat speaking with y...</td>\n",
              "      <td>[168, 6377, 36, 7, 2692, 1228, 15, 16, 82, 2, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6915a7f3-5948-4f8b-918f-d24364cb2d7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6915a7f3-5948-4f8b-918f-d24364cb2d7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6915a7f3-5948-4f8b-918f-d24364cb2d7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "test.data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU model "
      ],
      "metadata": {
        "id": "smLVgYaakYvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7USorwoIokp4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "17dg4rpmop0R"
      },
      "outputs": [],
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train.data['encoding'],maxlen = 500)\n",
        "y_train = encoded#train.data['h_e']\n",
        "X_test = sequence.pad_sequences(test.data['encoding'],maxlen=500)\n",
        "y_test = t_encoded#test.data['h_e']\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNglJ5YJqIPd",
        "outputId": "da5c332e-38cf-47fc-f7f4-7b3de517f49c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 32)           1280000   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 500, 32)           2080      \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 32)                2080      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,284,292\n",
            "Trainable params: 1,284,292\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 48s 228ms/step - loss: 1.0830 - accuracy: 0.4548\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 43s 217ms/step - loss: 0.9374 - accuracy: 0.5513\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 43s 215ms/step - loss: 0.3848 - accuracy: 0.8761\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 43s 216ms/step - loss: 0.0853 - accuracy: 0.9820\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 43s 215ms/step - loss: 0.0406 - accuracy: 0.9904\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 43s 214ms/step - loss: 0.0295 - accuracy: 0.9924\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 44s 221ms/step - loss: 0.0219 - accuracy: 0.9935\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 44s 218ms/step - loss: 0.0177 - accuracy: 0.9930\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 43s 217ms/step - loss: 0.0177 - accuracy: 0.9935\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 43s 216ms/step - loss: 0.0176 - accuracy: 0.9928\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 43s 215ms/step - loss: 0.0136 - accuracy: 0.9933\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 43s 216ms/step - loss: 0.0136 - accuracy: 0.9943\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 43s 216ms/step - loss: 0.0127 - accuracy: 0.9935\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 43s 217ms/step - loss: 0.0124 - accuracy: 0.9943\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 44s 218ms/step - loss: 0.0110 - accuracy: 0.9926\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 43s 217ms/step - loss: 0.0113 - accuracy: 0.9930\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 44s 218ms/step - loss: 0.0112 - accuracy: 0.9943\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 44s 218ms/step - loss: 0.0109 - accuracy: 0.9937\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 43s 216ms/step - loss: 0.0528 - accuracy: 0.9776\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 43s 216ms/step - loss: 0.1811 - accuracy: 0.9348\n",
            "Accuracy:  32.499998807907104\n"
          ]
        }
      ],
      "source": [
        "embedding_vector_length = 32\n",
        "model_RNN = Sequential()\n",
        "model_RNN.add(Embedding(40000,embedding_vector_length,input_length = 500))\n",
        "model_RNN.add(SimpleRNN(32,dropout=0.2, return_sequences = True ))\n",
        "model_RNN.add(SimpleRNN(32))\n",
        "model_RNN.add(Dense(4,activation = 'softmax'))\n",
        "model_RNN.compile(loss ='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model_RNN.summary())\n",
        "model_RNN.fit(X_train,y_train, epochs = 20, batch_size=23)\n",
        "\n",
        "scores = model_RNN.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN.save(\"/content/gdrive/MyDrive/NLP-Project\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4ChSeTplpM8",
        "outputId": "86971958-589f-4140-96a0-ff2b6dda6ae8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/NLP-Project/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-K_SWuGAecZg"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# filename = 'model_1.sav'\n",
        "# pickle.dump(model,open(filename,'wb'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "B-LghG347Nr-"
      },
      "outputs": [],
      "source": [
        "# type(X_train)\n",
        "\n",
        "# X_train = np.append(train.data['similarity'][:,np.newaxis], X_train, axis=1)\n",
        "# X_test = np.append(test.data['similarity'][:,np.newaxis],X_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-3lzA4pywwZ8"
      },
      "outputs": [],
      "source": [
        "coh_bin = []\n",
        "for i in range(4600):\n",
        "  if train.data['labelA'].tolist()[i] >=2:\n",
        "    coh_bin.append(1)\n",
        "  else:\n",
        "    coh_bin.append(0)\n",
        "train.data['bin_coh']= coh_bin\n",
        "\n",
        "\n",
        "coh_bin=[]\n",
        "for i in range(200):\n",
        "  if test.data['labelA'].tolist()[i] >=2:\n",
        "    coh_bin.append(1)\n",
        "  else:\n",
        "    coh_bin.append(0)\n",
        "\n",
        "test.data['bin_coh']=coh_bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7Q5r6H4yx3i_"
      },
      "outputs": [],
      "source": [
        "lst = array(train.data['bin_coh'])\n",
        "encoded = to_categorical(lst)\n",
        "\n",
        "lst = array(test.data['bin_coh'])\n",
        "t_encoded = to_categorical(lst)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6dERcvIFyWF2"
      },
      "outputs": [],
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train.data['encoding'],maxlen = 500)\n",
        "y_train = encoded#train.data['h_e']\n",
        "X_test = sequence.pad_sequences(test.data['encoding'],maxlen=500)\n",
        "y_test = t_encoded#test.data['h_e']\n",
        "\n",
        "# X_train = np.append(train.data['similarity'][:,np.newaxis], X_train, axis=1)\n",
        "# X_test = np.append(test.data['similarity'][:,np.newaxis],X_test, axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckWk6V9cyfWY",
        "outputId": "30ecc132-440d-44fd-8787-67cf22f5c161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 500, 32)           1280000   \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 500, 32)           2080      \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,284,226\n",
            "Trainable params: 1,284,226\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "200/200 [==============================] - 47s 225ms/step - loss: 0.6361 - accuracy: 0.6730\n",
            "Epoch 2/15\n",
            "200/200 [==============================] - 45s 223ms/step - loss: 0.5396 - accuracy: 0.7402\n",
            "Epoch 3/15\n",
            "200/200 [==============================] - 45s 223ms/step - loss: 0.1574 - accuracy: 0.9470\n",
            "Epoch 4/15\n",
            "200/200 [==============================] - 44s 220ms/step - loss: 0.0368 - accuracy: 0.9913\n",
            "Epoch 5/15\n",
            "200/200 [==============================] - 44s 220ms/step - loss: 0.0189 - accuracy: 0.9957\n",
            "Epoch 6/15\n",
            "200/200 [==============================] - 44s 222ms/step - loss: 0.0138 - accuracy: 0.9970\n",
            "Epoch 7/15\n",
            "200/200 [==============================] - 45s 224ms/step - loss: 0.0091 - accuracy: 0.9972\n",
            "Epoch 8/15\n",
            "200/200 [==============================] - 44s 221ms/step - loss: 0.0096 - accuracy: 0.9967\n",
            "Epoch 9/15\n",
            "200/200 [==============================] - 45s 223ms/step - loss: 0.0078 - accuracy: 0.9970\n",
            "Epoch 10/15\n",
            "200/200 [==============================] - 45s 225ms/step - loss: 0.0068 - accuracy: 0.9972\n",
            "Epoch 11/15\n",
            "200/200 [==============================] - 45s 223ms/step - loss: 0.0073 - accuracy: 0.9965\n",
            "Epoch 12/15\n",
            "200/200 [==============================] - 45s 223ms/step - loss: 0.1241 - accuracy: 0.9537\n",
            "Epoch 13/15\n",
            "200/200 [==============================] - 45s 223ms/step - loss: 0.1673 - accuracy: 0.9350\n",
            "Epoch 14/15\n",
            "200/200 [==============================] - 44s 222ms/step - loss: 0.1439 - accuracy: 0.9420\n",
            "Epoch 15/15\n",
            "200/200 [==============================] - 44s 222ms/step - loss: 0.0565 - accuracy: 0.9820\n",
            "Accuracy:  55.50000071525574\n"
          ]
        }
      ],
      "source": [
        "embedding_vector_length = 32\n",
        "model_RNN_B = Sequential()\n",
        "model_RNN_B.add(Embedding(40000,embedding_vector_length,input_length = 500))\n",
        "model_RNN_B.add(SimpleRNN(32,dropout=0.2, return_sequences = True ))\n",
        "model_RNN_B.add(SimpleRNN(32))\n",
        "model_RNN_B.add(Dense(2,activation = 'softmax'))\n",
        "model_RNN_B.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model_RNN_B.summary())\n",
        "model_RNN_B.fit(X_train,y_train, epochs = 15 , batch_size=23)\n",
        "\n",
        "scores = model_RNN_B.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))\n",
        "\n",
        "\n",
        "# embedding_vector_length = 32\n",
        "# model_RNN = Sequential()\n",
        "# model_RNN.add(Embedding(40000,embedding_vector_length,input_length = 500))\n",
        "# model_RNN.add(SimpleRNN(32,dropout=0.2, return_sequences = True ))\n",
        "# model_RNN.add(SimpleRNN(32))\n",
        "# model_RNN.add(Dense(4,activation = 'softmax'))\n",
        "# model_RNN.compile(loss ='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "# print(model_RNN.summary())\n",
        "# model_RNN.fit(X_train,y_train, epochs = 20, batch_size=23)\n",
        "\n",
        "# scores = model_RNN.evaluate(X_test, y_test, verbose =0)\n",
        "# print(\"Accuracy: \",(scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN_B.save(\"/content/gdrive/MyDrive/NLP-Project\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrMabokCquxC",
        "outputId": "759c82e7-8643-406e-bf66-be1491a1c2da"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/NLP-Project/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eQgrSud3uSdc"
      },
      "outputs": [],
      "source": [
        "train.data = similarity_paragraph(train.data)\n",
        "test.data = similarity_paragraph(test.data)\n",
        "\n",
        "len(train_mapping)\n",
        "# train_mapping\n",
        "train.data['encoding'] = train_mapping\n",
        "test.data['encoding'] = test_mapping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7)\n",
        "X_train = sequence.pad_sequences(train.data['encoding'],maxlen = 500)\n",
        "y_train = encoded#train.data['h_e']\n",
        "X_test = sequence.pad_sequences(test.data['encoding'],maxlen=500)\n",
        "y_test = t_encoded#test.data['h_e']\n",
        "\n",
        "X_train = np.append(train.data['similarity'][:,np.newaxis], X_train, axis=1)\n",
        "X_test = np.append(test.data['similarity'][:,np.newaxis],X_test, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBwN9V5MrslM",
        "outputId": "bd2d805a-a4f8-4ba1-e7a7-91184d2f633c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_length = 32\n",
        "model_RNN_C = Sequential()\n",
        "model_RNN_C.add(Embedding(40000,embedding_vector_length,input_length = 501))\n",
        "model_RNN_C.add(SimpleRNN(32,dropout=0.2, return_sequences = True ))\n",
        "model_RNN_C.add(SimpleRNN(32))\n",
        "model_RNN_C.add(Dense(2,activation = 'softmax'))\n",
        "model_RNN_C.compile(loss ='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "print(model_RNN_C.summary())\n",
        "model_RNN_C.fit(X_train,y_train, epochs = 15 , batch_size=23)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQyQmJV5rtY5",
        "outputId": "b3050ecc-1356-4824-9525-a1404c22e42f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 501, 32)           1280000   \n",
            "                                                                 \n",
            " simple_rnn_6 (SimpleRNN)    (None, 501, 32)           2080      \n",
            "                                                                 \n",
            " simple_rnn_7 (SimpleRNN)    (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,284,226\n",
            "Trainable params: 1,284,226\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "200/200 [==============================] - 48s 232ms/step - loss: 0.6357 - accuracy: 0.6698\n",
            "Epoch 2/15\n",
            "200/200 [==============================] - 45s 225ms/step - loss: 0.4941 - accuracy: 0.7637\n",
            "Epoch 3/15\n",
            "200/200 [==============================] - 45s 224ms/step - loss: 0.1463 - accuracy: 0.9491\n",
            "Epoch 4/15\n",
            "200/200 [==============================] - 44s 221ms/step - loss: 0.0381 - accuracy: 0.9911\n",
            "Epoch 5/15\n",
            "200/200 [==============================] - 44s 222ms/step - loss: 0.0207 - accuracy: 0.9952\n",
            "Epoch 6/15\n",
            "200/200 [==============================] - 45s 224ms/step - loss: 0.0177 - accuracy: 0.9950\n",
            "Epoch 7/15\n",
            "200/200 [==============================] - 45s 223ms/step - loss: 0.0158 - accuracy: 0.9961\n",
            "Epoch 8/15\n",
            "200/200 [==============================] - 45s 226ms/step - loss: 0.0111 - accuracy: 0.9967\n",
            "Epoch 9/15\n",
            "200/200 [==============================] - 45s 224ms/step - loss: 0.0135 - accuracy: 0.9957\n",
            "Epoch 10/15\n",
            "200/200 [==============================] - 45s 223ms/step - loss: 0.0118 - accuracy: 0.9965\n",
            "Epoch 11/15\n",
            "200/200 [==============================] - 45s 224ms/step - loss: 0.0107 - accuracy: 0.9970\n",
            "Epoch 12/15\n",
            "200/200 [==============================] - 45s 224ms/step - loss: 0.0114 - accuracy: 0.9961\n",
            "Epoch 13/15\n",
            "200/200 [==============================] - 45s 223ms/step - loss: 0.0079 - accuracy: 0.9974\n",
            "Epoch 14/15\n",
            "200/200 [==============================] - 45s 223ms/step - loss: 0.0075 - accuracy: 0.9974\n",
            "Epoch 15/15\n",
            "200/200 [==============================] - 45s 224ms/step - loss: 0.0063 - accuracy: 0.9967\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2f86f47d10>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model_RNN_C.evaluate(X_test, y_test, verbose =0)\n",
        "print(\"Accuracy: \",(scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2uCC98B3zkM",
        "outputId": "492cabaa-7610-45fc-81e8-4eb4ea9be3ac"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  53.50000262260437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN_C.save(\"/content/gdrive/MyDrive/NLP-Project\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m24eY_Nrx-d",
        "outputId": "b3525427-b587-49cc-8cf9-0e1d67903bf9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/NLP-Project/assets\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Textual_Coherence_RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}